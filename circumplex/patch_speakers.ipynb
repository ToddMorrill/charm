{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d70db5-2545-4ee9-8162-a0743985da5d",
   "metadata": {},
   "source": [
    "# Patch pickled dataset with speaker information for text conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3302a994-d1e0-4e29-b055-df1f997b932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8e63ea6",
   "metadata": {},
   "source": [
    "## Load data\n",
    "1. load the pickle file containing the complete dataset\n",
    "1. load the metadata associated with text message conversations so we can include speaker IDs in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd78fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle file\n",
    "data = utils.load_pickle('/mnt/swordfish-pool2/ccu/amith-cache.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab4d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all text conversations and determine if the metadata is present on this server\n",
    "text_conversations = {file_id: meta for file_id, meta in data.items() if meta['data_type'] == 'text'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b799346",
   "metadata": {},
   "outputs": [],
   "source": [
    "releases = set()\n",
    "more_than_one_corpora_issues = []\n",
    "not_present_issues = []\n",
    "for file_id, meta in text_conversations.items():\n",
    "    if len(meta['status_in_corpora']) != 1:\n",
    "        more_than_one_corpora_issues.append(file_id)\n",
    "        continue\n",
    "    if meta['status_in_corpora'][0][1] != 'present':\n",
    "        not_present_issues.append(file_id)\n",
    "        continue\n",
    "    releases.add(meta['status_in_corpora'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32379d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_present_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b37501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LDC2022E11_CCU_TA1_Mandarin_Chinese_Development_Source_Data_R1',\n",
       " 'LDC2022E22_CCU_TA1_Mandarin_Chinese_Mini_Evaluation_Source_Data',\n",
       " 'LDC2023E03_CCU_TA1_Mandarin_Chinese_Development_Source_Data_R4_V1.0',\n",
       " 'LDC2023E07_CCU_TA1_Mandarin_Chinese_Evaluation_Source_Data_V1.0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7196ee3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1767"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec910da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather up all text metadata files\n",
    "ltf_files = []\n",
    "psm_files = []\n",
    "for release in releases:\n",
    "    release_dir = os.path.join('/mnt/swordfish-pool2/ccu', release)\n",
    "    ltf_dir = os.path.join(release_dir, 'data/text/ltf')\n",
    "    psm_dir = os.path.join(release_dir, 'data/text/psm')\n",
    "    release_ltf_files = [os.path.join(ltf_dir, f) for f in os.listdir(ltf_dir) if f != '.DS_Store']\n",
    "    release_psm_files = [os.path.join(psm_dir, f) for f in os.listdir(psm_dir) if f != '.DS_Store']\n",
    "    ltf_files.extend(release_ltf_files)\n",
    "    psm_files.extend(release_psm_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e46df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4294, 4294)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ltf_files), len(psm_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd1dcd42-3b6a-439a-af5c-d9966277c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following functions retrieve speaker information for the conversation utterances\n",
    "def load_conversation(ltf_file, psm_file):\n",
    "    with open(ltf_file, 'r') as f:\n",
    "        ltf_content = f.read()\n",
    "    \n",
    "    try:\n",
    "        with open(psm_file, 'r') as f:\n",
    "            psm_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        psm_content = False\n",
    "    return ltf_content, psm_content\n",
    "\n",
    "def unpack_attributes(attribute):\n",
    "    attr_dict = {}\n",
    "    for attr in attribute:\n",
    "        attr_dict[attr['@name']] = attr['@value']\n",
    "    return attr_dict\n",
    "\n",
    "def merge_metadata(ltf_content, psm_content):\n",
    "    ltf = xmltodict.parse(ltf_content)\n",
    "    psm = xmltodict.parse(psm_content)\n",
    "    \n",
    "    # filter psm list to message attributes\n",
    "    message_attr = []\n",
    "    for d in psm['psm']['string']:\n",
    "        if d['@type'] == 'message':\n",
    "            message_attr.append(d)\n",
    "\n",
    "    # no message attributes, then data is not in BOLT format but rather\n",
    "    # from a discussion forum (see Release 4 README.md for more details)\n",
    "    if len(message_attr) == 0:\n",
    "        for d in psm['psm']['string']:\n",
    "            if d['@type'] == 'post':\n",
    "                message_attr.append(d)\n",
    "        \n",
    "    # unpack the message attributes\n",
    "    psm_df = pd.DataFrame(message_attr)\n",
    "    psm_attr_df = pd.DataFrame(psm_df['attribute'].apply(unpack_attributes).values.tolist())\n",
    "    \n",
    "    psm_df = pd.concat((psm_df.drop(columns=['attribute']), psm_attr_df), axis=1)\n",
    "    \n",
    "    ltf_df = pd.DataFrame(ltf['LCTL_TEXT']['DOC']['TEXT']['SEG'])\n",
    "    \n",
    "    # join ltf and psm on start_char\n",
    "    df = pd.merge(ltf_df, psm_df, left_on='@start_char', right_on='@begin_offset', how='left')\n",
    "    \n",
    "    # filter out messages where content length is 0 for a clean inner join\n",
    "    df = df[df['@char_length'] != '0'].reset_index(drop=True)\n",
    "    assert (len(df) == len(ltf_df))\n",
    "    # may still be missing attributes for each message\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3f9ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Mandarin_Chinese_Development_Source_Data_R1/data/text/ltf/M01000GAM.ltf.xml']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltf_files[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce5d1c6-16bc-404d-861d-717847cb377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4294/4294 [01:14<00:00, 57.54it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "errors = []\n",
    "for ltf_file in tqdm(ltf_files):\n",
    "    psm_file = ltf_file.replace('ltf', 'psm')\n",
    "    ltf_content, psm_content = load_conversation(ltf_file, psm_file)\n",
    "    if psm_content == False:\n",
    "        errors.append((ltf_file, psm_file, 'PSM file not found'))\n",
    "        continue\n",
    "    df = merge_metadata(ltf_content, psm_content)\n",
    "    \n",
    "    # for BOLT style conversations, the participant field is the speaker\n",
    "    if 'participant' in df.columns:\n",
    "        if len(df[df['participant'].isna()]) > 0:\n",
    "            errors.append((ltf_file, psm_file, 'participant field missing'))\n",
    "    elif 'author' in df.columns:\n",
    "        # TODO: we're missing authorship information for many of the lines\n",
    "        # need to better understand the data format\n",
    "        df.rename(columns={'author': 'participant'}, inplace=True)\n",
    "    # retain filename\n",
    "    df.insert(0, 'filename', ltf_file)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522f4128-41a4-4cce-bb40-5d2713c3172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(errors, columns=['ltf_file', 'psm_file', 'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "085dd5ad-21cc-49a1-aca4-2d100b450537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant field missing    5\n",
       "Name: error, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95cc4e5e-0abe-41af-ba5e-9f097895c336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0354dbe1-9400-4446-ae84-e1c2d841731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e9f941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>@id</th>\n",
       "      <th>@start_char</th>\n",
       "      <th>@end_char</th>\n",
       "      <th>ORIGINAL_TEXT</th>\n",
       "      <th>@type</th>\n",
       "      <th>@begin_offset</th>\n",
       "      <th>@char_length</th>\n",
       "      <th>id</th>\n",
       "      <th>participant</th>\n",
       "      <th>time</th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...</td>\n",
       "      <td>M01000GAM_0000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>你房子找咋样了？</td>\n",
       "      <td>message</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>m0000</td>\n",
       "      <td>135850</td>\n",
       "      <td>2013-05-04 00:24:19 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...</td>\n",
       "      <td>M01000GAM_0001</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>好郁闷啊……</td>\n",
       "      <td>message</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>m0001</td>\n",
       "      <td>135610</td>\n",
       "      <td>2013-05-04 00:27:40 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...</td>\n",
       "      <td>M01000GAM_0002</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>你几个人找</td>\n",
       "      <td>message</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>m0002</td>\n",
       "      <td>135850</td>\n",
       "      <td>2013-05-04 00:28:20 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...</td>\n",
       "      <td>M01000GAM_0003</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>我们人数波动……</td>\n",
       "      <td>message</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>m0003</td>\n",
       "      <td>135610</td>\n",
       "      <td>2013-05-04 00:29:21 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...</td>\n",
       "      <td>M01000GAM_0004</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>来我这住吧</td>\n",
       "      <td>message</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>m0004</td>\n",
       "      <td>135850</td>\n",
       "      <td>2013-05-04 00:29:49 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename             @id  \\\n",
       "0  /mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...  M01000GAM_0000   \n",
       "1  /mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...  M01000GAM_0001   \n",
       "2  /mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...  M01000GAM_0002   \n",
       "3  /mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...  M01000GAM_0003   \n",
       "4  /mnt/swordfish-pool2/ccu/LDC2022E11_CCU_TA1_Ma...  M01000GAM_0004   \n",
       "\n",
       "  @start_char @end_char ORIGINAL_TEXT    @type @begin_offset @char_length  \\\n",
       "0           0         7      你房子找咋样了？  message             0           10   \n",
       "1          10        15        好郁闷啊……  message            10            8   \n",
       "2          18        22         你几个人找  message            18            7   \n",
       "3          25        32      我们人数波动……  message            25           10   \n",
       "4          35        39         来我这住吧  message            35            7   \n",
       "\n",
       "      id participant                     time TOKEN datetime  \n",
       "0  m0000      135850  2013-05-04 00:24:19 UTC   NaN      NaN  \n",
       "1  m0001      135610  2013-05-04 00:27:40 UTC   NaN      NaN  \n",
       "2  m0002      135850  2013-05-04 00:28:20 UTC   NaN      NaN  \n",
       "3  m0003      135610  2013-05-04 00:29:21 UTC   NaN      NaN  \n",
       "4  m0004      135850  2013-05-04 00:29:49 UTC   NaN      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dab3032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388730"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6fcaf46-b640-4495-80d4-c5b12611a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_id'] = df['filename'].apply(lambda x: os.path.split(x)[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7db9a93-582f-4737-98c9-077c8817ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of conversations\n",
    "df['file_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d91215dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert @start_char to int\n",
    "df['@start_char'] = df['@start_char'].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "254c696b",
   "metadata": {},
   "source": [
    "## Merge speaker information back into pickled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7058062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1767/1767 [00:52<00:00, 33.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for file_id in tqdm(text_conversations):\n",
    "    temp_df = pd.DataFrame(data[file_id]['utterances'])\n",
    "    temp_df = temp_df.merge(df[df['file_id'] == file_id][['@start_char', 'participant']], left_on='start', right_on='@start_char', how='left', validate='1:1')\n",
    "    temp_df.drop(columns=['@start_char'], inplace=True)\n",
    "    temp_df.to_dict(orient='records')\n",
    "    data[file_id]['utterances'] = temp_df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1418801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save back to disk as pkl\n",
    "with open('/mnt/swordfish-pool2/ccu/tm3229-cache.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07f36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
