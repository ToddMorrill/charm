{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d70db5-2545-4ee9-8162-a0743985da5d",
   "metadata": {},
   "source": [
    "# Prepare documents to be labeled with social orientation tags by GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3302a994-d1e0-4e29-b055-df1f997b932f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from collections import deque\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from charm.data import utils as charm_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84eeff11",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# select which model to use\n",
    "model = 'gpt-3.5-turbo'\n",
    "token_limit = 4096\n",
    "# model = 'gpt-4'\n",
    "# token_limit = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd78fb4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load the pickle file\n",
    "data = utils.load_pickle(os.path.expanduser('~/Documents/data/charm/transformed/tm3229-cache.pkl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a5f25c2-070f-46a0-a0e1-0ce6afcab965",
   "metadata": {},
   "source": [
    "## Create GPT prompts\n",
    "Data preparation plan\n",
    "1. Convert participant IDs to speaker numbers\n",
    "1. Only annotate LDC annotated regions\n",
    "1. Prepare the data for all splits in chunks of 100 conversations\n",
    "    1. Prioritize internal train and val splits for starters\n",
    "1. Assess prices of processing everything\n",
    "1. Measure conversation length and split conversation into multiple chunks as needed\n",
    "1. Save to jsonl\n",
    "1. Merge in change point information (won't repeat this exercise due to concerns about the incorrectness of timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca6520f-f525-4b60-aa1f-2e6b6d071516",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def id_speakers_convo(group_df):\n",
    "    \"\"\"Give each speaker a numerical identifier.\"\"\"\n",
    "    if 'participant' not in group_df.columns:\n",
    "        group_df['participant_id'] = 'unknown'\n",
    "        return group_df\n",
    "    \n",
    "    # fillna with unknown\n",
    "    group_df['participant'] = group_df['participant'].fillna('unknown')\n",
    "\n",
    "    speaker_map = {}\n",
    "    for idx, participant in enumerate(group_df['participant'].unique()):\n",
    "        speaker_map[participant] = idx + 1\n",
    "\n",
    "    # apply speaker map to the participant column\n",
    "    group_df['participant_id'] = group_df['participant'].apply(lambda x: speaker_map[x])\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503066cf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# create conversation turn\n",
    "def create_line(row):\n",
    "    # TODO: could optionally include the time\n",
    "    return f\"Speaker {row['participant_id']} ({row['utterance_id']}): {row['text']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b823a827",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_gpt_lines(data, transcript='whisper'):\n",
    "    \"\"\"Records the following data in the data dict:\n",
    "        1. Gives a numeric ID to each speaker in a transcript\n",
    "        2. Creates utterance IDs for each utterance in a transcript\n",
    "        3. Creates a complete line that will be sent to GPT\n",
    "    \"\"\"\n",
    "    # for all file_ids, add a participant_id value to utterances\n",
    "    unprocessed = []\n",
    "    for file_id in tqdm(data.keys()):\n",
    "        if not data[file_id]['processed']:\n",
    "            unprocessed.append(file_id)\n",
    "            continue\n",
    "        # if data_type == 'text', don't need whisper key\n",
    "        if data[file_id]['data_type'] == 'text':\n",
    "            temp_df = pd.DataFrame(data[file_id]['utterances'])\n",
    "        else:\n",
    "            temp_df = pd.DataFrame(data[file_id]['utterances'][transcript])\n",
    "        \n",
    "        # add participant_id\n",
    "        temp_df = id_speakers_convo(temp_df)\n",
    "        # add utterance_id\n",
    "        # sort by start to be safe\n",
    "        temp_df = temp_df.sort_values(by='start', ascending=True)\n",
    "        temp_df = temp_df.reset_index(drop=True)\n",
    "        temp_df['utterance_id'] = temp_df.index + 1\n",
    "        # create GPT line\n",
    "        temp_df['gpt_line'] = temp_df.apply(create_line, axis=1)\n",
    "\n",
    "        # persist results\n",
    "        # if data_type == 'text', don't need whisper key\n",
    "        if data[file_id]['data_type'] == 'text':\n",
    "            # save results back to data\n",
    "            data[file_id]['utterances'] = temp_df.to_dict('records')\n",
    "        else:\n",
    "            # save results back to data\n",
    "            data[file_id]['utterances'][transcript] = temp_df.to_dict('records')\n",
    "    return data, unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae00372",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [01:08<00:00, 146.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data, unprocessed = prepare_gpt_lines(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0edf775",
   "metadata": {},
   "source": [
    "## Create GPT chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2dc89a7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load prompt\n",
    "with open('prompt.txt', 'r') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "# load prompt addendum for no speaker scenario\n",
    "with open('prompt_speaker_unknown.txt', 'r') as f:\n",
    "    prompt_speaker_unknown = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91d225f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# need some descriptive stats on distribution of conversation lengths in terms of encoding length\n",
    "encoding = tiktoken.encoding_for_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc76286",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# remove the last two lines of the prompt and add the speaker unknown prompt\n",
    "prompt_speaker_unknown = '\\n'.join(prompt.split('\\n')[:-2]) + '\\n' + prompt_speaker_unknown\n",
    "# model_input = prompt + '\\n'.join(sample_df['Complete Line'].tolist()) + '\\n\\nOutput:\\n'\n",
    "# model_input_speaker_unknown = prompt_speaker_unknown + '\\n'.join(sample_df['Complete Line (Unknown Speaker)'].tolist()) + '\\n\\nOutput:\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a760f9d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "prompt_length = len(encoding.encode(prompt))\n",
    "prompt_speaker_unknown_length = len(encoding.encode(prompt_speaker_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17316c09",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 962\n",
      "Prompt (speaker unknown) length: 1715\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt length: {prompt_length}\")\n",
    "print(f\"Prompt (speaker unknown) length: {prompt_speaker_unknown_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e76ec051",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max conversation input length (excluding prompt): 1567\n",
      "Max conversation input length (no speaker, excluding prompt): 1190\n"
     ]
    }
   ],
   "source": [
    "# GPT4 has a max length of 8192 so leave some fraction of generative capacity for the response\n",
    "# ie. (8192 - prompt length) / 2 = max length of input\n",
    "max_input_length = int((token_limit - len(encoding.encode(prompt))) / 2)\n",
    "print(f\"Max conversation input length (excluding prompt): {max_input_length}\")\n",
    "max_input_length_no_speaker = int((token_limit - len(encoding.encode(prompt_speaker_unknown))) / 2)\n",
    "print(f\"Max conversation input length (no speaker, excluding prompt): {max_input_length_no_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79dd23a5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [04:30<00:00, 37.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# create conversation chunks (again could probably speed this up with a DF and some indexing)\n",
    "# encode conversations with GPT-4 tokenizer\n",
    "# could probably do this faster if everything was in a single list/df\n",
    "convo_turn_lengths = []\n",
    "convo_encoding_lengths = []\n",
    "for file_id in tqdm(data.keys()):\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    if data[file_id]['data_type'] == 'text':\n",
    "        temp_df = pd.DataFrame(data[file_id]['utterances'])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data[file_id]['utterances']['whisper'])\n",
    "    \n",
    "    # filter temp_df to only annotated regions\n",
    "    # not doing this because of issues with Whisper timestamps\n",
    "    # temp_df = temp_df[(temp_df['start'] >= data[file_id]['start']) & (temp_df['end'] <= data[file_id]['end'])]\n",
    "    \n",
    "    convo_turn_lengths.append((file_id, data[file_id]['data_type'], len(temp_df)))\n",
    "    encoding_length = 0\n",
    "    encoding_lengths = []\n",
    "    encoding_cum_sum = []\n",
    "    encoded_content = encoding.encode_batch(temp_df['gpt_line'].values.tolist())\n",
    "    for encoded_line in encoded_content:\n",
    "        encoding_length += len(encoded_line)\n",
    "        encoding_lengths.append(len(encoded_line))\n",
    "        encoding_cum_sum.append(encoding_length)\n",
    "    temp_df['encoding_length'] = encoding_lengths\n",
    "    temp_df['encoding_cumsum'] = encoding_cum_sum\n",
    "    convo_encoding_lengths.append((file_id, data[file_id]['data_type'], encoding_length))\n",
    "\n",
    "    # save cumsum info back to data\n",
    "    if data[file_id]['data_type'] == 'text':\n",
    "        # save results back to data\n",
    "        data[file_id]['utterances'] = temp_df.to_dict('records')\n",
    "    else:\n",
    "        # save results back to data\n",
    "        data[file_id]['utterances']['whisper'] = temp_df.to_dict('records')\n",
    "    \n",
    "    # use the cumsum information to create dialog chunks with overlapping utterances for continuity\n",
    "    # identify indices where convo chunk is approx max_input_length\n",
    "    max_size = max_input_length if data[file_id]['data_type'] == 'text' else max_input_length_no_speaker\n",
    "    utterances = data[file_id]['utterances'] if data[file_id]['data_type'] == 'text' else data[file_id]['utterances']['whisper']\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    n_overlap = 10\n",
    "    last_n = deque([], maxlen=n_overlap)\n",
    "    idx_end = 0\n",
    "    while idx_end != len(utterances):\n",
    "        # mental model is to create a chunk that is as close to max_input_length as possible\n",
    "        # then move the idx_end to 10 utterances before idx_end to get some overlap and repeat\n",
    "        current_chunk.append(utterances[idx_end])\n",
    "        current_size += utterances[idx_end]['encoding_length']\n",
    "        last_n.append(utterances[idx_end]['encoding_length'])\n",
    "\n",
    "        # record chunk if filled or at end of utterances\n",
    "        if (current_size > max_size) or (idx_end == (len(utterances) - 1)):\n",
    "            # if the most recent n turns are too long, then don't reset idx_end, just continue\n",
    "            # prevents infinite loop\n",
    "            # or if at the end of the utterances, then don't reset idx_end\n",
    "            if (sum(last_n) > max_size) or (idx_end == (len(utterances) - 1)):\n",
    "                idx_end = idx_end\n",
    "            else:\n",
    "                idx_end = max(0, idx_end - n_overlap) # get some overlap with 10 previous utterances\n",
    "            # reset trackers\n",
    "            last_n.clear()\n",
    "            current_size = 0\n",
    "            chunks.append(current_chunk) \n",
    "            current_chunk = []\n",
    "        \n",
    "        # advance idx_end\n",
    "        idx_end += 1\n",
    "    \n",
    "    # save chunks back to data\n",
    "    data[file_id]['gpt_prompts'] = chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9aaf3ec",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "convo_turn_lengths_df = pd.DataFrame(convo_turn_lengths, columns=['file_id', 'data_type', 'num_turns'])\n",
    "convo_encoding_lengths_df = pd.DataFrame(convo_encoding_lengths, columns=['file_id', 'data_type', 'encoding_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f921c6b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">num_turns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>727.0</td>\n",
       "      <td>360.052270</td>\n",
       "      <td>308.962545</td>\n",
       "      <td>16.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>3640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>83.787776</td>\n",
       "      <td>70.766406</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>7474.0</td>\n",
       "      <td>394.418651</td>\n",
       "      <td>369.629549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>4905.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_turns                                                           \n",
       "              count        mean         std   min    25%    50%    75%     max\n",
       "data_type                                                                     \n",
       "audio         727.0  360.052270  308.962545  16.0  215.0  293.0  374.0  3640.0\n",
       "text         1767.0   83.787776   70.766406  15.0   40.0   64.0  105.0   959.0\n",
       "video        7474.0  394.418651  369.629549   1.0  204.0  311.0  475.0  4905.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_turn_lengths_df.groupby('data_type').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d934c8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">encoding_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>727.0</td>\n",
       "      <td>6033.680880</td>\n",
       "      <td>5344.089944</td>\n",
       "      <td>234.0</td>\n",
       "      <td>3911.0</td>\n",
       "      <td>4519.0</td>\n",
       "      <td>5599.5</td>\n",
       "      <td>69103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>2583.804754</td>\n",
       "      <td>2253.267471</td>\n",
       "      <td>354.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>3077.0</td>\n",
       "      <td>23254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>7474.0</td>\n",
       "      <td>7275.577870</td>\n",
       "      <td>6458.365181</td>\n",
       "      <td>215.0</td>\n",
       "      <td>3787.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>8212.5</td>\n",
       "      <td>82887.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          encoding_length                                                   \\\n",
       "                    count         mean          std    min     25%     50%   \n",
       "data_type                                                                    \n",
       "audio               727.0  6033.680880  5344.089944  234.0  3911.0  4519.0   \n",
       "text               1767.0  2583.804754  2253.267471  354.0  1223.0  1813.0   \n",
       "video              7474.0  7275.577870  6458.365181  215.0  3787.0  5453.0   \n",
       "\n",
       "                            \n",
       "              75%      max  \n",
       "data_type                   \n",
       "audio      5599.5  69103.0  \n",
       "text       3077.0  23254.0  \n",
       "video      8212.5  82887.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_encoding_lengths_df.groupby('data_type').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ba8c7c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check distribution of chunk lengths\n",
    "chunk_lengths = []\n",
    "for file_id in data.keys():\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    chunk_lengths.append((file_id, data[file_id]['data_type'], len(data[file_id]['gpt_prompts'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1666b9b5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">num_chunks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>727.0</td>\n",
       "      <td>6.359010</td>\n",
       "      <td>5.296355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>2.335597</td>\n",
       "      <td>2.015230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>7474.0</td>\n",
       "      <td>7.204576</td>\n",
       "      <td>6.120104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_chunks                                              \n",
       "               count      mean       std  min  25%  50%  75%   max\n",
       "data_type                                                         \n",
       "audio          727.0  6.359010  5.296355  1.0  4.0  5.0  6.0  69.0\n",
       "text          1767.0  2.335597  2.015230  1.0  1.0  2.0  3.0  22.0\n",
       "video         7474.0  7.204576  6.120104  1.0  4.0  5.0  8.0  81.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(chunk_lengths, columns=['file_id', 'data_type', 'num_chunks']).groupby('data_type').describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a814904",
   "metadata": {},
   "source": [
    "### Create Final GPT Prompts, Break into 100 Conversation Splits, Assess Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71ba9aee",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EVALUATION_LDC2023E07', 'INTERNAL_TEST', 'INTERNAL_TRAIN', 'INTERNAL_VAL'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split by train/val/test/eval\n",
    "# use the speaker unknown prompt for the video and audio data\n",
    "# get all splits\n",
    "splits = set()\n",
    "for file_id in data.keys():\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    # union with existing splits\n",
    "    splits = splits.union(data[file_id]['splits'])\n",
    "    \n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbc273ec",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [00:01<00:00, 7618.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_prompts = []\n",
    "val_prompts = []\n",
    "test_prompts = []\n",
    "eval_prompts = []\n",
    "for file_id in tqdm(data):\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    # retrieve chunks\n",
    "    chunks = data[file_id]['gpt_prompts']\n",
    "    preamble = prompt if data[file_id]['data_type'] == 'text' else prompt_speaker_unknown\n",
    "    file_gpt_messages = []\n",
    "    for chunk in chunks:        \n",
    "        final_prompt = preamble + '\\n'.join([utterance['gpt_line'] for utterance in chunk]) + '\\n\\nOutput:\\n'\n",
    "        # format GPT messages\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": final_prompt},\n",
    "            ]\n",
    "        file_gpt_messages.append([file_id, messages])\n",
    "    \n",
    "    if 'INTERNAL_TRAIN' in data[file_id]['splits']:\n",
    "        train_prompts.extend(file_gpt_messages)\n",
    "    elif 'INTERNAL_VAL' in data[file_id]['splits']:\n",
    "        val_prompts.extend(file_gpt_messages)\n",
    "    elif 'INTERNAL_TEST' in data[file_id]['splits']:\n",
    "        test_prompts.extend(file_gpt_messages)\n",
    "    elif 'EVALUATION_LDC2023E07' in data[file_id]['splits']:\n",
    "        eval_prompts.extend(file_gpt_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef7a0c6b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# tally up unique file ids in each split to make sure we have the right number\n",
    "train_file_id_count = len(set([file_id for file_id, _ in train_prompts]))\n",
    "val_file_id_count = len(set([file_id for file_id, _ in val_prompts]))\n",
    "test_file_id_count = len(set([file_id for file_id, _ in test_prompts]))\n",
    "eval_file_id_count = len(set([file_id for file_id, _ in eval_prompts]))\n",
    "processed_file_count = len([file_id for file_id in data.keys() if data[file_id]['processed']])\n",
    "assert train_file_id_count + val_file_id_count + test_file_id_count + eval_file_id_count == processed_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad7d60bf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 5 5 56\n"
     ]
    }
   ],
   "source": [
    "# split each split into chunks of 100 file_ids randomly by using a hash function\n",
    "train_hash_buckets = train_file_id_count // 100\n",
    "val_hash_buckets = val_file_id_count // 100\n",
    "test_hash_buckets = test_file_id_count // 100\n",
    "eval_hash_buckets = eval_file_id_count // 100\n",
    "print(train_hash_buckets, val_hash_buckets, test_hash_buckets, eval_hash_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96ed60fa",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def assign_to_hash_bucket(prompts, num_file_ids_per_bucket=100):\n",
    "    file_id_count = len(set([file_id for file_id, _ in prompts]))\n",
    "    num_hash_buckets = file_id_count // num_file_ids_per_bucket\n",
    "    # loop through files and assign to hash buckets\n",
    "    shards = {}\n",
    "    for file_id, messages in prompts:\n",
    "        hash_bucket = int(hashlib.sha256(file_id.encode('utf-8')).hexdigest(), 16) % num_hash_buckets\n",
    "        if hash_bucket not in shards:\n",
    "            shards[hash_bucket] = []\n",
    "        shards[hash_bucket].append([file_id, messages])\n",
    "    return shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "568560bc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_shards = assign_to_hash_bucket(train_prompts)\n",
    "val_shards = assign_to_hash_bucket(val_prompts)\n",
    "test_shards = assign_to_hash_bucket(test_prompts)\n",
    "eval_shards = assign_to_hash_bucket(eval_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "571c38e8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# assert that the total number of messages in train_shards matches train_prompts\n",
    "assert sum([len(train_shards[key]) for key in train_shards.keys()]) == len(train_prompts)\n",
    "assert sum([len(val_shards[key]) for key in val_shards.keys()]) == len(val_prompts)\n",
    "assert sum([len(test_shards[key]) for key in test_shards.keys()]) == len(test_prompts)\n",
    "assert sum([len(eval_shards[key]) for key in eval_shards.keys()]) == len(eval_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5bb5e4d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# calculate total cost\n",
    "def calculate_cost(data, shard, prompt_length, prompt_speaker_unknown_length, model='gpt-4'):\n",
    "    total_prompt_tokens = 0\n",
    "    estimated_output_tokens = 0\n",
    "    for file_id, messages in shard:\n",
    "        input_len = utils.num_tokens_from_messages(messages, model='gpt-4')\n",
    "        total_prompt_tokens += input_len\n",
    "        prompt_len_ = prompt_length if data[file_id]['data_type'] == 'text' else prompt_speaker_unknown_length\n",
    "        # responses seem to be much shorter than prompts\n",
    "        estimated_output_tokens += (input_len - prompt_len_) / 2 # probably an overestimate\n",
    "    # cost per 1000 tokens\n",
    "    prompt_cost = 0.03 if model == 'gpt-4' else 0.002\n",
    "    response_cost = 0.06 if model == 'gpt-4' else 0.002\n",
    "    input_cost = ((total_prompt_tokens/1000)*prompt_cost)\n",
    "    output_cost = ((estimated_output_tokens/1000)*response_cost)\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1662de38",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "shard_costs = {}\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    shard_costs[name] = {}\n",
    "    for shard in split.keys():\n",
    "        shard_costs[name][shard] = calculate_cost(data, split[shard], prompt_length, prompt_speaker_unknown_length, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dec7f5a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# convert shard costs to a dataframe\n",
    "shard_costs_df = pd.DataFrame(shard_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8cc2c35",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.149060</td>\n",
       "      <td>3.693544</td>\n",
       "      <td>3.622777</td>\n",
       "      <td>4.783058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.524640</td>\n",
       "      <td>0.454993</td>\n",
       "      <td>0.751800</td>\n",
       "      <td>0.649478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.829947</td>\n",
       "      <td>2.995734</td>\n",
       "      <td>2.628138</td>\n",
       "      <td>3.182713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.781194</td>\n",
       "      <td>3.549116</td>\n",
       "      <td>3.277541</td>\n",
       "      <td>4.397372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.192907</td>\n",
       "      <td>3.743929</td>\n",
       "      <td>3.464696</td>\n",
       "      <td>4.757459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.531407</td>\n",
       "      <td>4.043519</td>\n",
       "      <td>4.319820</td>\n",
       "      <td>5.148559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.023166</td>\n",
       "      <td>4.135420</td>\n",
       "      <td>4.423690</td>\n",
       "      <td>6.513060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train       val      test       eval\n",
       "count  33.000000  5.000000  5.000000  56.000000\n",
       "mean    4.149060  3.693544  3.622777   4.783058\n",
       "std     0.524640  0.454993  0.751800   0.649478\n",
       "min     2.829947  2.995734  2.628138   3.182713\n",
       "25%     3.781194  3.549116  3.277541   4.397372\n",
       "50%     4.192907  3.743929  3.464696   4.757459\n",
       "75%     4.531407  4.043519  4.319820   5.148559\n",
       "max     5.023166  4.135420  4.423690   6.513060"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_costs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a34b6df",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    136.918984\n",
       "val       18.467718\n",
       "test      18.113885\n",
       "eval     267.851243\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_costs_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b14fe2d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# retrieve 1 document of each type from train_shard 0\n",
    "video = None\n",
    "text = None\n",
    "audio = None\n",
    "for file_id, messages in train_shards[0]:\n",
    "    if data[file_id]['data_type'] == 'video':\n",
    "        video = file_id\n",
    "    elif data[file_id]['data_type'] == 'text':\n",
    "        text = file_id\n",
    "    elif data[file_id]['data_type'] == 'audio':\n",
    "        audio = file_id\n",
    "\n",
    "video_messages = []\n",
    "audio_messages = []\n",
    "text_messages = []\n",
    "# retain all the messages for these selected files\n",
    "for file_id, messages in train_prompts:\n",
    "    if file_id == video:\n",
    "        video_messages.append([file_id, messages])\n",
    "    elif file_id == audio:\n",
    "        audio_messages.append([file_id, messages])\n",
    "    elif file_id == text:\n",
    "        text_messages.append([file_id, messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b019475",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# create data directory\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b5f05fb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save these messages to a jsonl file, train_shard_0_sample.jsonl\n",
    "with open('./data/train_shard_0_sample.jsonl', 'w') as f:\n",
    "    all_messages = video_messages + audio_messages + text_messages\n",
    "    for m in all_messages:\n",
    "        json_string = json.dumps(m)\n",
    "        f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc7da52d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def count_utterances(data, shard):\n",
    "    # get all unique file ids in this shard\n",
    "    file_ids = set([file_id for file_id, _ in shard])\n",
    "    # count the number of utterances in the actual prompt and then compare to the number of utterances in the file\n",
    "    actual_utterances = 0\n",
    "    gpt_utterances = 0\n",
    "    for file_id in file_ids:\n",
    "        utterances = data[file_id]['utterances'] if data[file_id]['data_type'] == 'text' else data[file_id]['utterances']['whisper']\n",
    "        actual_utterances += len(utterances)\n",
    "    # get the number of utterances in the gpt prompt\n",
    "    for file_id, messages in shard:\n",
    "        gpt_utterances += len(messages[1]['content'].split('Input:\\n')[-1].split('\\n')[:-3])\n",
    "        \n",
    "    return actual_utterances, gpt_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20c187de",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# tally up how many utterances are in each shard\n",
    "shard_utterances_counts = {}\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    shard_utterances_counts[name] = {}\n",
    "    for shard in split.keys():\n",
    "        actual_utterances, gpt_utterances = count_utterances(data, split[shard])\n",
    "        shard_utterances_counts[name][shard] = {'actual_utterances': actual_utterances, 'gpt_utterances': gpt_utterances}['actual_utterances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20cd58f5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "utterance_counts = pd.DataFrame(shard_utterances_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a1eccb6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26043.484848</td>\n",
       "      <td>30825.20000</td>\n",
       "      <td>29979.200000</td>\n",
       "      <td>39182.839286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3461.614048</td>\n",
       "      <td>3491.59687</td>\n",
       "      <td>6456.704322</td>\n",
       "      <td>5274.111271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18954.000000</td>\n",
       "      <td>25032.00000</td>\n",
       "      <td>21889.000000</td>\n",
       "      <td>28260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23331.000000</td>\n",
       "      <td>30891.00000</td>\n",
       "      <td>26640.000000</td>\n",
       "      <td>35823.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25981.000000</td>\n",
       "      <td>31050.00000</td>\n",
       "      <td>28578.000000</td>\n",
       "      <td>38715.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28687.000000</td>\n",
       "      <td>33507.00000</td>\n",
       "      <td>34680.000000</td>\n",
       "      <td>42641.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34865.000000</td>\n",
       "      <td>33646.00000</td>\n",
       "      <td>38109.000000</td>\n",
       "      <td>52794.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train          val          test          eval\n",
       "count     33.000000      5.00000      5.000000     56.000000\n",
       "mean   26043.484848  30825.20000  29979.200000  39182.839286\n",
       "std     3461.614048   3491.59687   6456.704322   5274.111271\n",
       "min    18954.000000  25032.00000  21889.000000  28260.000000\n",
       "25%    23331.000000  30891.00000  26640.000000  35823.750000\n",
       "50%    25981.000000  31050.00000  28578.000000  38715.500000\n",
       "75%    28687.000000  33507.00000  34680.000000  42641.750000\n",
       "max    34865.000000  33646.00000  38109.000000  52794.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbd70f95",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save shards to disk\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    for shard in split.keys():\n",
    "        with open(f'./data/{name}_shard_{shard}.jsonl', 'w') as f:\n",
    "            for file_id, messages in split[shard]:\n",
    "                json_string = json.dumps([file_id, messages])\n",
    "                f.write(json_string + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b25207ee",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save updated pickle file\n",
    "with open(os.path.expanduser('~/Documents/data/charm/transformed/tm3229-cache-updated.json'), 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f7dbf7c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# delete files, as needed\n",
    "# import glob\n",
    "# for name in ['train', 'val', 'test', 'eval']:\n",
    "#     for file in glob.glob(f'./data/{name}_shard_*'):\n",
    "#         os.remove(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d7962c7",
   "metadata": {},
   "source": [
    "### Graveyard (old code) - though some of this may be much faster (e.g. using a DF instead of a list of dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "954aeb21-73e7-494d-8327-28deae2c5caa",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# df['Complete Line Length'] =  df['Complete Line'].apply(lambda x: len(encoding.encode(x)))\n",
    "# def group_cumsum(group_df):\n",
    "#     group_df['line_len_cumsum'] = group_df['Complete Line Length'].cumsum()\n",
    "#     return group_df\n",
    "# df = df.groupby('file_id', group_keys=False).apply(group_cumsum)\n",
    "# # for each conversation, create a message\n",
    "# temp_df = df[df['file_id'] == 'M01000GE2']\n",
    "# conversation_string = '\\n'.join(temp_df['Complete Line'].values)\n",
    "# messages = [\n",
    "#   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#   {\"role\": \"user\", \"content\": prompt},\n",
    "# ]\n",
    "\n",
    "# # check length, first check with just the prompt\n",
    "# prompt_len = num_tokens_from_messages(messages)\n",
    "\n",
    "# model_input = prompt + conversation_string\n",
    "# # then check the whole convo and get the diff\n",
    "# messages = [\n",
    "#   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#   {\"role\": \"user\", \"content\": model_input},\n",
    "# ]\n",
    "\n",
    "# input_len = num_tokens_from_messages(messages)\n",
    "\n",
    "# leftover = 4_096 - input_len\n",
    "# # want capacity of about 2500 tokens for the model, which means convo must be less than\n",
    "# # 4,096 - 2000 - prompt_len\n",
    "# convo_target_len = 4_096 - 2250 - prompt_len\n",
    "# convo_target_len\n",
    "# # loop over conversations and generate complete prompts\n",
    "# prompts = []\n",
    "# for file_id in df['file_id'].unique():\n",
    "#     file_df = df[df['file_id'] == file_id]\n",
    "\n",
    "#     # identify indices where convo chunk is approx convo_target_len\n",
    "#     start = 0\n",
    "#     end = convo_target_len\n",
    "#     idx_end = 0\n",
    "#     while idx_end+1 != len(file_df):\n",
    "#         chunk_df = file_df[(file_df['line_len_cumsum'] > start) & (file_df['line_len_cumsum'] <= end)]\n",
    "#         idx_start = chunk_df.iloc[0].name\n",
    "#         idx_end = chunk_df.iloc[-1].name\n",
    "        \n",
    "#         # create model input\n",
    "#         conversation_string = '\\n'.join(file_df.iloc[idx_start:idx_end+1]['Complete Line'].values)\n",
    "#         model_input = prompt + conversation_string\n",
    "        \n",
    "#         messages = [\n",
    "#           {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\"},\n",
    "#           {\"role\": \"user\", \"content\": model_input},\n",
    "#         ]\n",
    "#         prompts.append([file_id, messages])\n",
    "\n",
    "#         # update start and end\n",
    "#         start = chunk_df.iloc[-1]['line_len_cumsum']\n",
    "#         end = start + convo_target_len\n",
    "# prompts[0][1]\n",
    "# print(prompts[0][-1][-1]['content'])\n",
    "# # estimate cost\n",
    "# token_count = 0\n",
    "# for p in prompts:\n",
    "#     token_count += num_tokens_from_messages(p[-1])\n",
    "# # price\n",
    "# (token_count / 1000) * 0.002\n",
    "# os.makedirs('data', exist_ok=True)\n",
    "# # save to disk\n",
    "# # filename = \"data/gpt_requests.jsonl\"\n",
    "\n",
    "# # with open(filename, \"w\") as f:\n",
    "# #     for p in prompts:\n",
    "# #         json_string = json.dumps(p)\n",
    "# #         f.write(json_string + \"\\n\")\n",
    "# df['filename'].nunique()\n",
    "# len(df)\n",
    "# df.merge(meta_df.drop_duplicates(subset=['file_uid']), left_on='file_id', right_on='file_uid', how='left')['release'].value_counts()\n",
    "# df\n",
    "# # save the final df to disk\n",
    "# df.rename(columns={'social_orientation': 'social_orientation_random'}, inplace=True)\n",
    "# circumplex_dir = os.path.join(data_dir, 'transformed/circumplex')\n",
    "# os.makedirs(circumplex_dir, exist_ok=True)\n",
    "# save_filepath = os.path.join(circumplex_dir, 'gpt_prompts_r1_mini_eval_text.csv')\n",
    "# df.to_csv(save_filepath, index=False)\n",
    "# # run GPT on the prompts\n",
    "# ## Merge change points into utterances\n",
    "# # for each file_id, convert participants to numbers\n",
    "# df = df.groupby('filename', group_keys=False).apply(id_speakers)\n",
    "# df['@begin_offset'] = df['@begin_offset'].astype(int)\n",
    "# df['@char_length'] = df['@char_length'].astype(int)\n",
    "# def merge_changepoints(group_df, change_point_anno_df):\n",
    "#     # identify file_i\n",
    "#     file_id = group_df['file_id'].iloc[0]\n",
    "#     file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id].sort_values(by='timestamp')\n",
    "#     # merge in changepoint data\n",
    "#     merged_df = pd.merge_asof(group_df, file_df[['timestamp', 'impact_scalar', 'comment']], left_on='@begin_offset', right_on='timestamp', direction='nearest')\n",
    "#     # remove invalid matches\n",
    "#     # TODO: this doesn't solve for the issue of multiple changepoints in one utterance\n",
    "#     greater_equal = merged_df['@begin_offset'] <= merged_df['timestamp']\n",
    "#     less = merged_df['timestamp'] < (merged_df['@begin_offset'] + merged_df['@char_length'])\n",
    "#     merged_df.loc[~(greater_equal & less), ['timestamp', 'impact_scalar', 'comment']] = np.nan\n",
    "#     return merged_df\n",
    "# from functools import partial\n",
    "# merge_changepoints_partial = partial(merge_changepoints, change_point_anno_df=change_point_anno_df)\n",
    "# change_point_anno_df['timestamp'] = change_point_anno_df['timestamp'].astype(int)\n",
    "# file_id = 'M01000GZR'\n",
    "# file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id]\n",
    "# df = df.groupby('file_id', group_keys=False).apply(merge_changepoints_partial)\n",
    "# df['timestamp'].notnull().sum()\n",
    "# change_point_anno_df['file_id'].isin(text_file_ids).sum()\n",
    "# # check that all change points available were used\n",
    "# # assert df['timestamp'].notnull().sum() == change_point_anno_df['file_id'].isin(text_file_ids).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CHARM)",
   "language": "python",
   "name": "charm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
