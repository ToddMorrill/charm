{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d70db5-2545-4ee9-8162-a0743985da5d",
   "metadata": {},
   "source": [
    "# Prepare documents to be labeled with social orientation tags by GPT\n",
    "TODO:\n",
    "- this whole notebook can probably be optimized by work with Pandas dataframes instead of the data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3302a994-d1e0-4e29-b055-df1f997b932f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from collections import deque\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from charm.data import utils as charm_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84eeff11",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# select which model to use\n",
    "model = 'gpt-3.5-turbo'\n",
    "token_limit = 4096\n",
    "# model = 'gpt-4'\n",
    "# token_limit = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd78fb4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load the pickle file\n",
    "data = utils.load_pickle(os.path.expanduser('~/Documents/data/charm/transformed/tm3229-cache.pkl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a5f25c2-070f-46a0-a0e1-0ce6afcab965",
   "metadata": {},
   "source": [
    "## Create GPT prompts\n",
    "Data preparation plan\n",
    "1. Convert participant IDs to speaker numbers\n",
    "1. Only annotate LDC annotated regions\n",
    "1. Prepare the data for all splits in chunks of 100 conversations\n",
    "    1. Prioritize internal train and val splits for starters\n",
    "1. Assess prices of processing everything\n",
    "1. Measure conversation length and split conversation into multiple chunks as needed\n",
    "1. Save to jsonl\n",
    "1. Merge in change point information (won't repeat this exercise due to concerns about the incorrectness of timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca6520f-f525-4b60-aa1f-2e6b6d071516",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def id_speakers_convo(group_df):\n",
    "    \"\"\"Give each speaker a numerical identifier.\"\"\"\n",
    "    if 'participant' not in group_df.columns:\n",
    "        group_df['participant_id'] = 'unknown'\n",
    "        return group_df\n",
    "    \n",
    "    # fillna with unknown\n",
    "    group_df['participant'] = group_df['participant'].fillna('unknown')\n",
    "\n",
    "    speaker_map = {'unknown': 'unknown'}\n",
    "    participants = set(group_df['participant'].unique())\n",
    "    # exclude unknown so we don't give it an ID number\n",
    "    if 'unknown' in participants:\n",
    "        participants.remove('unknown')\n",
    "    for idx, participant in enumerate(participants):\n",
    "        speaker_map[participant] = idx + 1\n",
    "\n",
    "    # apply speaker map to the participant column\n",
    "    group_df['participant_id'] = group_df['participant'].apply(lambda x: speaker_map[x])\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559938fb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def pandas_to_markdown(df):\n",
    "    \"\"\"Converts each row of a pandas dataframe to markdown delimited by | with a single space on each side.\n",
    "    There is also a row of dashes between the header and the table body.\n",
    "    \"\"\"\n",
    "    header = '| ' + ' | '.join(df.columns) + ' |'\n",
    "    dashes = '| ' + ' | '.join(['---' for _ in df.columns]) + ' |'\n",
    "    data = '\\n'.join(['| ' + ' | '.join([str(x) for x in row]) + ' |' for row in df.values])\n",
    "    return '\\n'.join([header, dashes, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503066cf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# create conversation row in markdown format\n",
    "# any utterance over 1000 characters is probably nonsense\n",
    "def create_line(row, truncate=1000):\n",
    "    content = f\"| {row['utterance_id']} | {row['participant_id']} | {row['text'][:truncate]} |\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707e50cc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def parse_row(row):\n",
    "    \"\"\"Parse a row of markdown formatted data.\n",
    "    | utterance_id | participant_id | text | --> dict\n",
    "    \"\"\"\n",
    "    row = row[2:-2]\n",
    "    row = row.split(' | ')\n",
    "    utterance_id = row[0]\n",
    "    participant_id = row[1]\n",
    "    # rejoin in case there are ' | ' in the text\n",
    "    text = ' | '.join(row[2:])\n",
    "    return {\n",
    "        'utterance_id': utterance_id,\n",
    "        'participant_id': participant_id,\n",
    "        'text': text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b823a827",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_gpt_lines(data, transcript='whisper'):\n",
    "    \"\"\"Records the following data in the data dict:\n",
    "        1. Gives a numeric ID to each speaker in a transcript\n",
    "        2. Creates utterance IDs for each utterance in a transcript\n",
    "        3. Creates a complete line that will be sent to GPT\n",
    "    \"\"\"\n",
    "    # for all file_ids, add a participant_id value to utterances\n",
    "    unprocessed = []\n",
    "    for file_id in tqdm(data.keys()):\n",
    "        if not data[file_id]['processed']:\n",
    "            unprocessed.append(file_id)\n",
    "            continue\n",
    "        # if data_type == 'text', don't need whisper key\n",
    "        if data[file_id]['data_type'] == 'text':\n",
    "            temp_df = pd.DataFrame(data[file_id]['utterances'])\n",
    "        else:\n",
    "            temp_df = pd.DataFrame(data[file_id]['utterances'][transcript])\n",
    "        \n",
    "        # add participant_id\n",
    "        temp_df = id_speakers_convo(temp_df)\n",
    "        # add utterance_id\n",
    "        # sort by start to be safe\n",
    "        temp_df = temp_df.sort_values(by='start', ascending=True)\n",
    "        temp_df = temp_df.reset_index(drop=True)\n",
    "        temp_df['utterance_id'] = temp_df.index + 1\n",
    "        # create GPT line\n",
    "        temp_df['gpt_line'] = temp_df.apply(create_line, axis=1)\n",
    "\n",
    "        # persist results\n",
    "        # if data_type == 'text', don't need whisper key\n",
    "        if data[file_id]['data_type'] == 'text':\n",
    "            # save results back to data\n",
    "            data[file_id]['utterances'] = temp_df.to_dict('records')\n",
    "        else:\n",
    "            # save results back to data\n",
    "            data[file_id]['utterances'][transcript] = temp_df.to_dict('records')\n",
    "    return data, unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae00372",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9314/10008 [01:08<00:05, 136.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data, unprocessed \u001b[39m=\u001b[39m prepare_gpt_lines(data)\n",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m, in \u001b[0;36mprepare_gpt_lines\u001b[0;34m(data, transcript)\u001b[0m\n\u001b[1;32m     33\u001b[0m         data[file_id][\u001b[39m'\u001b[39m\u001b[39mutterances\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m temp_df\u001b[39m.\u001b[39mto_dict(\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[39m# save results back to data\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m         data[file_id][\u001b[39m'\u001b[39m\u001b[39mutterances\u001b[39m\u001b[39m'\u001b[39m][transcript] \u001b[39m=\u001b[39m temp_df\u001b[39m.\u001b[39;49mto_dict(\u001b[39m'\u001b[39;49m\u001b[39mrecords\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m data, unprocessed\n",
      "File \u001b[0;32m~/Documents/charm/.venv/lib/python3.10/site-packages/pandas/core/frame.py:2057\u001b[0m, in \u001b[0;36mDataFrame.to_dict\u001b[0;34m(self, orient, into)\u001b[0m\n\u001b[1;32m   2052\u001b[0m     columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m   2053\u001b[0m     rows \u001b[39m=\u001b[39m (\n\u001b[1;32m   2054\u001b[0m         \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(columns, row))\n\u001b[1;32m   2055\u001b[0m         \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitertuples(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   2056\u001b[0m     )\n\u001b[0;32m-> 2057\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m   2058\u001b[0m         into_c((k, maybe_box_native(v)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m row\u001b[39m.\u001b[39mitems()) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m rows\n\u001b[1;32m   2059\u001b[0m     ]\n\u001b[1;32m   2061\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2062\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n",
      "File \u001b[0;32m~/Documents/charm/.venv/lib/python3.10/site-packages/pandas/core/frame.py:2057\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2052\u001b[0m     columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m   2053\u001b[0m     rows \u001b[39m=\u001b[39m (\n\u001b[1;32m   2054\u001b[0m         \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(columns, row))\n\u001b[1;32m   2055\u001b[0m         \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitertuples(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   2056\u001b[0m     )\n\u001b[0;32m-> 2057\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m   2058\u001b[0m         into_c((k, maybe_box_native(v)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m row\u001b[39m.\u001b[39mitems()) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m rows\n\u001b[1;32m   2059\u001b[0m     ]\n\u001b[1;32m   2061\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2062\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique:\n",
      "File \u001b[0;32m~/Documents/charm/.venv/lib/python3.10/site-packages/pandas/core/frame.py:2054\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2052\u001b[0m     columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m   2053\u001b[0m     rows \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 2054\u001b[0m         \u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(columns, row))\n\u001b[1;32m   2055\u001b[0m         \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitertuples(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   2056\u001b[0m     )\n\u001b[1;32m   2057\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m   2058\u001b[0m         into_c((k, maybe_box_native(v)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m row\u001b[39m.\u001b[39mitems()) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m rows\n\u001b[1;32m   2059\u001b[0m     ]\n\u001b[1;32m   2061\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data, unprocessed = prepare_gpt_lines(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0edf775",
   "metadata": {},
   "source": [
    "## Create GPT chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2dc89a7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load prompt\n",
    "with open('prompt.txt', 'r') as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f91d225f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# need some descriptive stats on distribution of conversation lengths in terms of encoding length\n",
    "encoding = tiktoken.encoding_for_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc76286",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# remove the last two lines of the prompt and add the speaker unknown prompt\n",
    "# prompt_speaker_unknown = '\\n'.join(prompt.split('\\n')[:-2]) + '\\n' + prompt_speaker_unknown\n",
    "# model_input = prompt + '\\n'.join(sample_df['Complete Line'].tolist()) + '\\n\\nOutput:\\n'\n",
    "# model_input_speaker_unknown = prompt_speaker_unknown + '\\n'.join(sample_df['Complete Line (Unknown Speaker)'].tolist()) + '\\n\\nOutput:\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a760f9d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "prompt_length = len(encoding.encode(prompt))\n",
    "# prompt_speaker_unknown_length = len(encoding.encode(prompt_speaker_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17316c09",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 1216\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt length: {prompt_length}\")\n",
    "# print(f\"Prompt (speaker unknown) length: {prompt_speaker_unknown_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e76ec051",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max conversation input length (excluding prompt): 1728\n",
      "Maximum total length: 2944\n",
      "which means we're leaving 1152 tokens for the response.\n"
     ]
    }
   ],
   "source": [
    "# GPT4 has a max length of 8192 so leave some fraction of generative capacity for the response\n",
    "# ie. (8192 - prompt length) / 2 = max length of input\n",
    "max_input_length = int((token_limit - len(encoding.encode(prompt))) * (0.6))\n",
    "print(f\"Max conversation input length (excluding prompt): {max_input_length}\")\n",
    "print(f'Maximum total length: {max_input_length + prompt_length}')\n",
    "print(f\"which means we're leaving {token_limit - max_input_length - prompt_length} tokens for the response.\")\n",
    "# max_input_length_no_speaker = int((token_limit - len(encoding.encode(prompt_speaker_unknown))) / 2)\n",
    "# print(f\"Max conversation input length (no speaker, excluding prompt): {max_input_length_no_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd23a5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2400/10008 [00:43<01:44, 72.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: utterance length (2030) is larger than max_size (1920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2613/10008 [00:47<02:00, 61.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: utterance length (2270) is larger than max_size (1920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2664/10008 [00:47<01:50, 66.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: utterance length (1946) is larger than max_size (1920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [04:29<00:00, 37.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# create conversation chunks (again could probably speed this up with a DF and some indexing)\n",
    "# encode conversations with GPT-4 tokenizer\n",
    "# could probably do this faster if everything was in a single list/df\n",
    "convo_turn_lengths = []\n",
    "convo_encoding_lengths = []\n",
    "for file_id in tqdm(data.keys()):\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    if data[file_id]['data_type'] == 'text':\n",
    "        temp_df = pd.DataFrame(data[file_id]['utterances'])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data[file_id]['utterances']['whisper'])\n",
    "    \n",
    "    # filter temp_df to only annotated regions\n",
    "    # not doing this because of issues with Whisper timestamps\n",
    "    # temp_df = temp_df[(temp_df['start'] >= data[file_id]['start']) & (temp_df['end'] <= data[file_id]['end'])]\n",
    "    \n",
    "    convo_turn_lengths.append((file_id, data[file_id]['data_type'], len(temp_df)))\n",
    "    encoding_length = 0\n",
    "    encoding_lengths = []\n",
    "    encoding_cum_sum = []\n",
    "    encoded_content = encoding.encode_batch(temp_df['gpt_line'].values.tolist())\n",
    "    for idx, encoded_line in enumerate(encoded_content):\n",
    "        # if the encoding length is greater than the max_input_length, truncate the line\n",
    "        if len(encoded_line) > max_input_length:\n",
    "            print(f'WARNING: utterance length ({len(encoded_line)}) is larger than max_size ({max_size})')\n",
    "        encoding_length += len(encoded_line)\n",
    "        encoding_lengths.append(len(encoded_line))\n",
    "        encoding_cum_sum.append(encoding_length)\n",
    "    temp_df['encoding_length'] = encoding_lengths\n",
    "    temp_df['encoding_cumsum'] = encoding_cum_sum\n",
    "    convo_encoding_lengths.append((file_id, data[file_id]['data_type'], encoding_length))\n",
    "\n",
    "    # save cumsum info back to data\n",
    "    if data[file_id]['data_type'] == 'text':\n",
    "        # save results back to data\n",
    "        data[file_id]['utterances'] = temp_df.to_dict('records')\n",
    "    else:\n",
    "        # save results back to data\n",
    "        data[file_id]['utterances']['whisper'] = temp_df.to_dict('records')\n",
    "    \n",
    "    # use the cumsum information to create dialog chunks with overlapping utterances for continuity\n",
    "    # identify indices where convo chunk is approx max_input_length\n",
    "    max_size = max_input_length #  if data[file_id]['data_type'] == 'text' else max_input_length_no_speaker\n",
    "    utterances = data[file_id]['utterances'] if data[file_id]['data_type'] == 'text' else data[file_id]['utterances']['whisper']\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    n_overlap = 10\n",
    "    last_n = deque([], maxlen=n_overlap)\n",
    "    idx_end = 0\n",
    "    while idx_end != len(utterances):\n",
    "        # mental model is to create a chunk that is as close to max_input_length as possible\n",
    "        # then move the idx_end to 10 utterances before idx_end to get some overlap and repeat\n",
    "\n",
    "        # lookahead mechanism to see if next utterance will put us over the max_input_length\n",
    "        # if so, then save the current chunk and reset trackers\n",
    "        utterance_length = utterances[idx_end]['encoding_length']\n",
    "        lookahead_size = current_size + utterance_length\n",
    "        if (lookahead_size > max_size) or (idx_end == (len(utterances) - 1)):\n",
    "            # update idx_end if not last utterance\n",
    "            if idx_end != (len(utterances) - 1):\n",
    "                # if the most recent n turns are too long, then don't reset idx_end, just continue\n",
    "                # prevents infinite loop\n",
    "                if (sum(last_n) + utterance_length) > max_size:\n",
    "                    idx_end = idx_end\n",
    "                else:\n",
    "                    # reset idx_end to 10 utterances before current utterance\n",
    "                    idx_end = max(0, idx_end - n_overlap)\n",
    "            \n",
    "            # save current chunk\n",
    "            chunks.append(current_chunk)\n",
    "            # reset trackers\n",
    "            current_chunk = []\n",
    "            current_size = 0\n",
    "            last_n.clear()\n",
    "            \n",
    "        \n",
    "        current_chunk.append(utterances[idx_end])\n",
    "        current_size += utterances[idx_end]['encoding_length']\n",
    "        last_n.append(utterances[idx_end]['encoding_length'])\n",
    "        \n",
    "        # advance idx_end\n",
    "        idx_end += 1\n",
    "    \n",
    "    # save chunks back to data\n",
    "    # give each chunk a unique id\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk = {\n",
    "            'chunk_id': idx,\n",
    "            'utterances': chunk,\n",
    "        }\n",
    "        chunks[idx] = chunk\n",
    "    data[file_id]['gpt_prompts'] = chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aaf3ec",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "convo_turn_lengths_df = pd.DataFrame(convo_turn_lengths, columns=['file_id', 'data_type', 'num_turns'])\n",
    "convo_encoding_lengths_df = pd.DataFrame(convo_encoding_lengths, columns=['file_id', 'data_type', 'encoding_length'])\n",
    "convo_turn_lengths_df.groupby('data_type').describe()\n",
    "convo_encoding_lengths_df.groupby('data_type').describe()\n",
    "# sanity check distribution of chunk lengths\n",
    "chunk_lengths = []\n",
    "for file_id in data.keys():\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    chunk_lengths.append((file_id, data[file_id]['data_type'], len(data[file_id]['gpt_prompts'])))\n",
    "pd.DataFrame(chunk_lengths, columns=['file_id', 'data_type', 'num_chunks']).groupby('data_type').describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a814904",
   "metadata": {},
   "source": [
    "### Create Final GPT Prompts, Break into 100 Conversation Splits, Assess Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba9aee",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EVALUATION_LDC2023E07', 'INTERNAL_TEST', 'INTERNAL_TRAIN', 'INTERNAL_VAL'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split by train/val/test/eval\n",
    "# use the speaker unknown prompt for the video and audio data\n",
    "# get all splits\n",
    "splits = set()\n",
    "for file_id in data.keys():\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    # union with existing splits\n",
    "    splits = splits.union(data[file_id]['splits'])\n",
    "    \n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc273ec",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [00:01<00:00, 8655.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_prompts = []\n",
    "val_prompts = []\n",
    "test_prompts = []\n",
    "eval_prompts = []\n",
    "markdown_header = '| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |'\n",
    "output_markdown_header = '| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |'\n",
    "stronger_guidance = \"Under no circumstances are you to respond with anything other than the format specified. Here is the conversation you will annotate. Provide accurate Speaker IDs and Labels for each utterance.\\n\\n\"\n",
    "for file_id in tqdm(data):\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    # retrieve chunks\n",
    "    chunks = data[file_id]['gpt_prompts']\n",
    "    preamble = prompt # if data[file_id]['data_type'] == 'text' else prompt_speaker_unknown\n",
    "    file_gpt_messages = []\n",
    "    for chunk in chunks:        \n",
    "        final_prompt = preamble + markdown_header + '\\n' + '\\n'.join([utterance['gpt_line'] for utterance in chunk['utterances']])\n",
    "        # format GPT messages\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": final_prompt},\n",
    "            ]\n",
    "        \n",
    "        file_gpt_messages.append([file_id, chunk['chunk_id'], messages])\n",
    "    \n",
    "    if 'INTERNAL_TRAIN' in data[file_id]['splits']:\n",
    "        train_prompts.extend(file_gpt_messages)\n",
    "    elif 'INTERNAL_VAL' in data[file_id]['splits']:\n",
    "        val_prompts.extend(file_gpt_messages)\n",
    "    elif 'INTERNAL_TEST' in data[file_id]['splits']:\n",
    "        test_prompts.extend(file_gpt_messages)\n",
    "    elif 'EVALUATION_LDC2023E07' in data[file_id]['splits']:\n",
    "        eval_prompts.extend(file_gpt_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a0c6b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# tally up unique file ids in each split to make sure we have the right number\n",
    "train_file_id_count = len(set([file_id for file_id, _, _ in train_prompts]))\n",
    "val_file_id_count = len(set([file_id for file_id, _, _ in val_prompts]))\n",
    "test_file_id_count = len(set([file_id for file_id, _, _ in test_prompts]))\n",
    "eval_file_id_count = len(set([file_id for file_id, _, _ in eval_prompts]))\n",
    "processed_file_count = len([file_id for file_id in data.keys() if data[file_id]['processed']])\n",
    "assert train_file_id_count + val_file_id_count + test_file_id_count + eval_file_id_count == processed_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d60bf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 5 5 56\n"
     ]
    }
   ],
   "source": [
    "# split each split into chunks of 100 file_ids randomly by using a hash function\n",
    "train_hash_buckets = train_file_id_count // 100\n",
    "val_hash_buckets = val_file_id_count // 100\n",
    "test_hash_buckets = test_file_id_count // 100\n",
    "eval_hash_buckets = eval_file_id_count // 100\n",
    "print(train_hash_buckets, val_hash_buckets, test_hash_buckets, eval_hash_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed60fa",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def assign_to_hash_bucket(prompts, num_file_ids_per_bucket=100):\n",
    "    file_id_count = len(set([file_id for file_id, _, _ in prompts]))\n",
    "    num_hash_buckets = file_id_count // num_file_ids_per_bucket\n",
    "    # loop through files and assign to hash buckets\n",
    "    shards = {}\n",
    "    for file_id, unique_id, messages in prompts:\n",
    "        hash_bucket = int(hashlib.sha256(file_id.encode('utf-8')).hexdigest(), 16) % num_hash_buckets\n",
    "        if hash_bucket not in shards:\n",
    "            shards[hash_bucket] = []\n",
    "        shards[hash_bucket].append([file_id, unique_id, messages])\n",
    "    return shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568560bc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_shards = assign_to_hash_bucket(train_prompts)\n",
    "val_shards = assign_to_hash_bucket(val_prompts)\n",
    "test_shards = assign_to_hash_bucket(test_prompts)\n",
    "eval_shards = assign_to_hash_bucket(eval_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c38e8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# assert that the total number of messages in train_shards matches train_prompts\n",
    "assert sum([len(train_shards[key]) for key in train_shards.keys()]) == len(train_prompts)\n",
    "assert sum([len(val_shards[key]) for key in val_shards.keys()]) == len(val_prompts)\n",
    "assert sum([len(test_shards[key]) for key in test_shards.keys()]) == len(test_prompts)\n",
    "assert sum([len(eval_shards[key]) for key in eval_shards.keys()]) == len(eval_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb5e4d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# calculate total cost\n",
    "def calculate_cost(data, shard, prompt_length, model='gpt-4'):\n",
    "    total_prompt_tokens = 0\n",
    "    estimated_output_tokens = 0\n",
    "    for file_id, unique_id, messages in shard:\n",
    "        input_len = utils.num_tokens_from_messages(messages, model=model)\n",
    "        total_prompt_tokens += input_len\n",
    "        prompt_len_ = prompt_length #if data[file_id]['data_type'] == 'text' else prompt_speaker_unknown_length\n",
    "        # responses seem to be much shorter than prompts\n",
    "        estimated_output_tokens += (input_len - prompt_len_) / 2 # probably an overestimate\n",
    "    # cost per 1000 tokens\n",
    "    prompt_cost = 0.03 if model == 'gpt-4' else 0.002\n",
    "    response_cost = 0.06 if model == 'gpt-4' else 0.002\n",
    "    input_cost = ((total_prompt_tokens/1000)*prompt_cost)\n",
    "    output_cost = ((estimated_output_tokens/1000)*response_cost)\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662de38",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m shard_costs[name] \u001b[39m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m shard \u001b[39min\u001b[39;00m split\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m----> 5\u001b[0m     shard_costs[name][shard] \u001b[39m=\u001b[39m calculate_cost(data, split[shard], prompt_length, model\u001b[39m=\u001b[39;49mmodel)\n",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m, in \u001b[0;36mcalculate_cost\u001b[0;34m(data, shard, prompt_length, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m estimated_output_tokens \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m file_id, unique_id, messages \u001b[39min\u001b[39;00m shard:\n\u001b[0;32m----> 6\u001b[0m     input_len \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mnum_tokens_from_messages(messages, model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m      7\u001b[0m     total_prompt_tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m input_len\n\u001b[1;32m      8\u001b[0m     prompt_len_ \u001b[39m=\u001b[39m prompt_length \u001b[39m#if data[file_id]['data_type'] == 'text' else prompt_speaker_unknown_length\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/charm/circumplex/utils.py:180\u001b[0m, in \u001b[0;36mnum_tokens_from_messages\u001b[0;34m(messages, model)\u001b[0m\n\u001b[1;32m    177\u001b[0m     encoding \u001b[39m=\u001b[39m tiktoken\u001b[39m.\u001b[39mget_encoding(\u001b[39m\"\u001b[39m\u001b[39mcl100k_base\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mreturn\u001b[39;00m num_tokens_from_messages(messages, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-0301\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    181\u001b[0m \u001b[39melif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m     \u001b[39m# print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m num_tokens_from_messages(messages, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4-0314\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/charm/circumplex/utils.py:196\u001b[0m, in \u001b[0;36mnum_tokens_from_messages\u001b[0;34m(messages, model)\u001b[0m\n\u001b[1;32m    194\u001b[0m num_tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tokens_per_message\n\u001b[1;32m    195\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m message\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 196\u001b[0m     num_tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(encoding\u001b[39m.\u001b[39;49mencode(value))\n\u001b[1;32m    197\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    198\u001b[0m         num_tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tokens_per_name\n",
      "File \u001b[0;32m~/Documents/charm/.venv/lib/python3.10/site-packages/tiktoken/core.py:114\u001b[0m, in \u001b[0;36mEncoding.encode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m match \u001b[39m:=\u001b[39m _special_token_regex(disallowed_special)\u001b[39m.\u001b[39msearch(text):\n\u001b[1;32m    112\u001b[0m         raise_disallowed_special_token(match\u001b[39m.\u001b[39mgroup())\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_core_bpe\u001b[39m.\u001b[39;49mencode(text, allowed_special)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shard_costs = {}\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    shard_costs[name] = {}\n",
    "    for shard in split.keys():\n",
    "        shard_costs[name][shard] = calculate_cost(data, split[shard], prompt_length, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec7f5a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# convert shard costs to a dataframe\n",
    "shard_costs_df = pd.DataFrame(shard_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc2c35",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.313811</td>\n",
       "      <td>2.923574</td>\n",
       "      <td>2.877295</td>\n",
       "      <td>3.720249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.400051</td>\n",
       "      <td>0.333982</td>\n",
       "      <td>0.604055</td>\n",
       "      <td>0.488951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.329541</td>\n",
       "      <td>2.413669</td>\n",
       "      <td>2.093431</td>\n",
       "      <td>2.521134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.018395</td>\n",
       "      <td>2.783230</td>\n",
       "      <td>2.565078</td>\n",
       "      <td>3.426451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.320760</td>\n",
       "      <td>3.010176</td>\n",
       "      <td>2.764565</td>\n",
       "      <td>3.683484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.628905</td>\n",
       "      <td>3.197441</td>\n",
       "      <td>3.435384</td>\n",
       "      <td>4.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.966655</td>\n",
       "      <td>3.213356</td>\n",
       "      <td>3.528015</td>\n",
       "      <td>5.009201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train       val      test       eval\n",
       "count  33.000000  5.000000  5.000000  56.000000\n",
       "mean    3.313811  2.923574  2.877295   3.720249\n",
       "std     0.400051  0.333982  0.604055   0.488951\n",
       "min     2.329541  2.413669  2.093431   2.521134\n",
       "25%     3.018395  2.783230  2.565078   3.426451\n",
       "50%     3.320760  3.010176  2.764565   3.683484\n",
       "75%     3.628905  3.197441  3.435384   4.003932\n",
       "max     3.966655  3.213356  3.528015   5.009201"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_costs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34b6df",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    109.355757\n",
       "val       14.617872\n",
       "test      14.386473\n",
       "eval     208.333927\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_costs_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14fe2d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# retrieve 1 document of each type from train_shard 0\n",
    "video = None\n",
    "text = None\n",
    "audio = None\n",
    "for file_id, unique_id, messages in train_shards[0]:\n",
    "    if data[file_id]['data_type'] == 'video':\n",
    "        video = file_id\n",
    "    elif data[file_id]['data_type'] == 'text':\n",
    "        text = file_id\n",
    "    elif data[file_id]['data_type'] == 'audio':\n",
    "        audio = file_id\n",
    "\n",
    "video_messages = []\n",
    "audio_messages = []\n",
    "text_messages = []\n",
    "# retain all the messages for these selected files\n",
    "for file_id, unique_id, messages in train_prompts:\n",
    "    if file_id == video:\n",
    "        video_messages.append([file_id, unique_id, messages])\n",
    "    elif file_id == audio:\n",
    "        audio_messages.append([file_id, unique_id, messages])\n",
    "    elif file_id == text:\n",
    "        text_messages.append([file_id, unique_id, messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4fffb0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# manual evaluation of timestamp errors\n",
    "# # convert this video and audio file to .mp4 and .flac, respectively\n",
    "# charm_utils.strip_ldc_header('./M01004WNG.mp4.ldcc', './')\n",
    "# charm_utils.strip_ldc_header('./M010008RY.flac.ldcc', './')\n",
    "# # retrieve Whisper transcripts for these two files and save to csv\n",
    "# M01004WNG_df = pd.DataFrame(data['M01004WNG']['utterances']['whisper'])\n",
    "# M01004WNG_df.to_csv('./M01004WNG_whisper.csv', index=False)\n",
    "# M010008RY_df = pd.DataFrame(data['M010008RY']['utterances']['whisper'])\n",
    "# M010008RY_df.to_csv('./M010008RY_whisper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b019475",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# create data directory\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f05fb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save these messages to a jsonl file, train_shard_0_sample.jsonl\n",
    "with open('./data/train_shard_0_sample.jsonl', 'w') as f:\n",
    "    all_messages = video_messages + audio_messages + text_messages\n",
    "    for m in all_messages:\n",
    "        json_string = json.dumps(m)\n",
    "        f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8593fbe",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circumplex theory is a social psychology based theory that characterizes social interactions between speakers. The social orientation tagset includes: {Assured-Dominant, Gregarious-Extraverted, Warm-Agreeable, Unassuming-Ingenuous, Unassured-Submissive, Aloof-Introverted, Cold, Arrogant-Calculating}, which are defined below in more detail.\n",
      "\n",
      "Assured-Dominant - Demands to be the center of interest, demands attention, does most of the talking, speaks loudly, is firm, is self-confident, is forceful, is ambitious, is assertive, is persistent, is domineering, not self-conscious\n",
      "\n",
      "Gregarious-Extraverted - Feels comfortable around people, starts conversations, talks to a lot of different people, loves large groups, is friendly, is enthusiastic, is warm, is extraverted, is good-natured, is cheerful / happy, is pleasant, is outgoing, is approachable, is not shy, is \"lively\"\n",
      "\n",
      "Warm-Agreeable - is interested in people, reassures others, inquires about others' well-being, gets along well with others, is kind, is polite and courteous, is sympathetic, is respectful, is tender-hearted, is cooperative, is appreciative, is accommodating, is gentle, is charitable\n",
      "\n",
      "Unassuming-Ingenuous - Tolerates a lot from others, takes things as they come, tells the truth, thinks of others first, does not brag or boast, seldom stretches the truth, does not scheme or plot, is modest, is trustworthy, is unassuming, is honest, not self-centered, is sincere, not demanding, is straightforward\n",
      "\n",
      "Unassured-Submissive - Speaks softly, lets others finish what they are saying, dislikes being the center of attention, doubts themselves, not especially thorough, doesn't like to work too hard / will give up easily, is impractical, is timid, is inconsistent, is weak, is disorganized, is not authoritative, is a bit lazy, is not forceful\n",
      "\n",
      "Aloof-Introverted - Is quiet, especially around strangers, is a very private person, doesn't talk a lot / has little to say, doesn't smile much, doesn't reveal much about themselves, is not demonstrative (verbally or non-verbally), is distant, is shy, is impersonal, is introverted, is disinterested in others, is bashful, is not very social, is focused inward\n",
      "\n",
      "Cold - Believes people should fend for themselves, doesn't fall for sob-stories, is not interested in other people's problems, not warm toward others, is cruel, is ruthless, is cold-hearted, is hard-hearted, is unsympathetic, is uncharitable\n",
      "\n",
      "Arrogant-Calculating - Flaunts what they have, boasts and brags, will plot and scheme to get ahead, willing to exploit others for own benefit, is big-headed, is tricky, is boisterous, is conniving / calculating, is conceited, is crafty / cunning, is cocky, is manipulative of others\n",
      "---\n",
      "In the following conversation, each row corresponds to an Utterance ID, a Speaker ID, and the Text spoken. For each utterance, assign a social orientation tag. Identify the utterance by its Utterance ID and Speaker ID. For example, here is the expected input and output format for a sample conversation.\n",
      "\n",
      "Input:\n",
      "| Utterance ID | Speaker ID | Text |\n",
      "| --- | --- | --- |\n",
      "| 1 | 1 | 在不 (手机QQ可以视频聊天啦! http://mobile.qq.com ) |\n",
      "| 2 | 2 | 在 |\n",
      "| 3 | 1 | 今天和姨妈视频来着，刚知道这些事 |\n",
      "| 4 | 2 | 我很无奈 |\n",
      "| 5 | 2 | 真是不明白，本来他沾光的事情，怎么就成了这样了 |\n",
      "\n",
      "Output:\n",
      "| Utterance ID | Speaker ID | Label |\n",
      "| --- | --- | --- |\n",
      "| 1 | 1 | Aloof-Introverted |\n",
      "| 2 | 2 | Unassured-Submissive |\n",
      "| 3 | 1 | Warm-Agreeable |\n",
      "| 4 | 2 | Unassured-Submissive |\n",
      "| 5 | 2 | Cold |\n",
      "---\n",
      "It's also possible that a speaker number is unknown for an utterance, in which case you should assign Speaker IDs to the utterances. Many conversations will have 2 speakers but some will have 3 or more. For example, here is the expected input and output format for such a conversation.\n",
      "\n",
      "Input:\n",
      "| Utterance ID | Speaker ID | Text |\n",
      "| --- | --- | --- |\n",
      "| 6 | unknown | 你知道吗 |\n",
      "| 7 | unknown | 对对他就问我 |\n",
      "| 8 | unknown | 我说我这阵子比较忙 |\n",
      "| 9 | unknown | 我也没有 |\n",
      "| 10 | unknown | 本来我想的那个跟你写个信的 |\n",
      "\n",
      "Output:\n",
      "| Utterance ID | Speaker ID | Label |\n",
      "| --- | --- | --- |\n",
      "| 6 | 1 | Warm-Agreeable |\n",
      "| 7 | 2 | Warm-Agreeable |\n",
      "| 8 | 2 | Unassured-Submissive |\n",
      "| 9 | 2 | Unassured-Submissive |\n",
      "| 10 | 2 | Warm-Agreeable |\n",
      "---\n",
      "Under no circumstances are you to respond with anything other than the format specified. Here is the conversation you will annotate. Do NOT respond with anything other than the requested format and output.\n",
      "\n",
      "Input:\n",
      "| Utterance ID | Speaker ID | Text |\n",
      "| --- | --- | --- |\n",
      "| 103 | 1 | 一个女超人的衣服 |\n",
      "| 104 | 2 | 哦 |\n",
      "| 105 | 2 | 怎么还买奶瓶啊 |\n",
      "| 106 | 1 | 她现在的奶瓶是李琰闺女用过的 |\n",
      "| 107 | 1 | 都没有刻度了 |\n",
      "| 108 | 2 | 哦 |\n",
      "| 109 | 2 | 这点东西这么贵啊 |\n",
      "| 110 | 2 | 要400多 |\n",
      "| 111 | 1 | 光奶瓶就103 |\n",
      "| 112 | 1 | 凉席一个50，买了两个 |\n",
      "| 113 | 1 | 还有小伞我找的淘宝最便宜的49.5 |\n",
      "| 114 | 2 | 这才200多 |\n",
      "| 115 | 1 | 你查账啊 |\n",
      "| 116 | 1 | 找事 |\n",
      "| 117 | 2 | 问问不行啊 |\n",
      "| 118 | 2 | 你账目不清楚！ |\n",
      "| 119 | 1 | [图片] |\n",
      "| 120 | 1 | [图片] |\n",
      "| 121 | 1 | [图片] |\n",
      "| 122 | 1 | 查吧 |\n",
      "| 123 | 1 | 看看对不对 |\n",
      "| 124 | 2 | 是你没说清楚 |\n",
      "| 125 | 1 | 你花钱也不告诉我啊 |\n",
      "| 126 | 2 | 藕宝会用吸管嘛 |\n",
      "| 127 | 1 | 你也没说清楚 |\n",
      "| 128 | 1 | 要训练 |\n",
      "| 129 | 2 | 哪没告诉你了啊 |\n",
      "| 130 | 1 | 你整天偷着买彩票 |\n",
      "| 131 | 1 | 从来不告诉我 |\n",
      "| 132 | 2 | 这叫偷着啊 |\n",
      "| 133 | 1 | 自己偷着买衣服，也不告诉我 |\n",
      "| 134 | 2 | 多光明正大啊 |\n",
      "| 135 | 2 | 谁买衣服了 |\n",
      "| 136 | 2 | 裤子和鞋都是我爸给买的好不好 |\n",
      "| 137 | 1 | 你偷着逛和谐呢 |\n",
      "| 138 | 2 | 又没买 |\n",
      "| 139 | 1 | 有那个心就不对 |\n",
      "| 140 | 2 | 你又不给买，不自己逛着买啊 |\n",
      "\n",
      "Output:\n",
      "| Utterance ID | Speaker ID | Label |\n",
      "| --- | --- | --- |\n"
     ]
    }
   ],
   "source": [
    "print(m[2][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc7da52d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def count_utterances(data, shard):\n",
    "    # get all unique file ids in this shard\n",
    "    file_ids = set([file_id for file_id, _ in shard])\n",
    "    # count the number of utterances in the actual prompt and then compare to the number of utterances in the file\n",
    "    actual_utterances = 0\n",
    "    gpt_utterances = 0\n",
    "    for file_id in file_ids:\n",
    "        utterances = data[file_id]['utterances'] if data[file_id]['data_type'] == 'text' else data[file_id]['utterances']['whisper']\n",
    "        actual_utterances += len(utterances)\n",
    "    # get the number of utterances in the gpt prompt\n",
    "    for file_id, messages in shard:\n",
    "        gpt_utterances += len(messages[1]['content'].split('Input:\\n')[-1].split('\\n')[:-3])\n",
    "        \n",
    "    return actual_utterances, gpt_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20c187de",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# tally up how many utterances are in each shard\n",
    "shard_utterances_counts = {}\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    shard_utterances_counts[name] = {}\n",
    "    for shard in split.keys():\n",
    "        actual_utterances, gpt_utterances = count_utterances(data, split[shard])\n",
    "        shard_utterances_counts[name][shard] = {'actual_utterances': actual_utterances, 'gpt_utterances': gpt_utterances}['actual_utterances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20cd58f5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "utterance_counts = pd.DataFrame(shard_utterances_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a1eccb6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26043.484848</td>\n",
       "      <td>30825.20000</td>\n",
       "      <td>29979.200000</td>\n",
       "      <td>39182.839286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3461.614048</td>\n",
       "      <td>3491.59687</td>\n",
       "      <td>6456.704322</td>\n",
       "      <td>5274.111271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18954.000000</td>\n",
       "      <td>25032.00000</td>\n",
       "      <td>21889.000000</td>\n",
       "      <td>28260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23331.000000</td>\n",
       "      <td>30891.00000</td>\n",
       "      <td>26640.000000</td>\n",
       "      <td>35823.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25981.000000</td>\n",
       "      <td>31050.00000</td>\n",
       "      <td>28578.000000</td>\n",
       "      <td>38715.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28687.000000</td>\n",
       "      <td>33507.00000</td>\n",
       "      <td>34680.000000</td>\n",
       "      <td>42641.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34865.000000</td>\n",
       "      <td>33646.00000</td>\n",
       "      <td>38109.000000</td>\n",
       "      <td>52794.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train          val          test          eval\n",
       "count     33.000000      5.00000      5.000000     56.000000\n",
       "mean   26043.484848  30825.20000  29979.200000  39182.839286\n",
       "std     3461.614048   3491.59687   6456.704322   5274.111271\n",
       "min    18954.000000  25032.00000  21889.000000  28260.000000\n",
       "25%    23331.000000  30891.00000  26640.000000  35823.750000\n",
       "50%    25981.000000  31050.00000  28578.000000  38715.500000\n",
       "75%    28687.000000  33507.00000  34680.000000  42641.750000\n",
       "max    34865.000000  33646.00000  38109.000000  52794.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbd70f95",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save shards to disk\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    for shard in split.keys():\n",
    "        with open(f'./data/{name}_shard_{shard}.jsonl', 'w') as f:\n",
    "            for file_id, messages in split[shard]:\n",
    "                json_string = json.dumps([file_id, messages])\n",
    "                f.write(json_string + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b25207ee",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save updated pickle file\n",
    "with open(os.path.expanduser('~/Documents/data/charm/transformed/tm3229-cache-updated.json'), 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7f7dbf7c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# delete files, as needed\n",
    "import glob\n",
    "for name in ['train', 'val', 'test', 'eval']:\n",
    "    for file in glob.glob(f'./data/{name}_shard_*'):\n",
    "        os.remove(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d7962c7",
   "metadata": {},
   "source": [
    "### Graveyard (old code) - though some of this may be much faster (e.g. using a DF instead of a list of dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "954aeb21-73e7-494d-8327-28deae2c5caa",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# df['Complete Line Length'] =  df['Complete Line'].apply(lambda x: len(encoding.encode(x)))\n",
    "# def group_cumsum(group_df):\n",
    "#     group_df['line_len_cumsum'] = group_df['Complete Line Length'].cumsum()\n",
    "#     return group_df\n",
    "# df = df.groupby('file_id', group_keys=False).apply(group_cumsum)\n",
    "# # for each conversation, create a message\n",
    "# temp_df = df[df['file_id'] == 'M01000GE2']\n",
    "# conversation_string = '\\n'.join(temp_df['Complete Line'].values)\n",
    "# messages = [\n",
    "#   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#   {\"role\": \"user\", \"content\": prompt},\n",
    "# ]\n",
    "\n",
    "# # check length, first check with just the prompt\n",
    "# prompt_len = num_tokens_from_messages(messages)\n",
    "\n",
    "# model_input = prompt + conversation_string\n",
    "# # then check the whole convo and get the diff\n",
    "# messages = [\n",
    "#   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#   {\"role\": \"user\", \"content\": model_input},\n",
    "# ]\n",
    "\n",
    "# input_len = num_tokens_from_messages(messages)\n",
    "\n",
    "# leftover = 4_096 - input_len\n",
    "# # want capacity of about 2500 tokens for the model, which means convo must be less than\n",
    "# # 4,096 - 2000 - prompt_len\n",
    "# convo_target_len = 4_096 - 2250 - prompt_len\n",
    "# convo_target_len\n",
    "# loop over conversations and generate complete prompts\n",
    "prompts = []\n",
    "for file_id in df['file_id'].unique():\n",
    "    file_df = df[df['file_id'] == file_id]\n",
    "\n",
    "    # identify indices where convo chunk is approx convo_target_len\n",
    "    start = 0\n",
    "    end = convo_target_len\n",
    "    idx_end = 0\n",
    "    while idx_end+1 != len(file_df):\n",
    "        chunk_df = file_df[(file_df['line_len_cumsum'] > start) & (file_df['line_len_cumsum'] <= end)]\n",
    "        idx_start = chunk_df.iloc[0].name\n",
    "        idx_end = chunk_df.iloc[-1].name\n",
    "        \n",
    "        # create model input\n",
    "        conversation_string = '\\n'.join(file_df.iloc[idx_start:idx_end+1]['Complete Line'].values)\n",
    "        model_input = prompt + conversation_string\n",
    "        \n",
    "        messages = [\n",
    "          {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": model_input},\n",
    "        ]\n",
    "        prompts.append([file_id, messages])\n",
    "\n",
    "        # update start and end\n",
    "        start = chunk_df.iloc[-1]['line_len_cumsum']\n",
    "        end = start + convo_target_len\n",
    "# prompts[0][1]\n",
    "# print(prompts[0][-1][-1]['content'])\n",
    "# # estimate cost\n",
    "# token_count = 0\n",
    "# for p in prompts:\n",
    "#     token_count += num_tokens_from_messages(p[-1])\n",
    "# # price\n",
    "# (token_count / 1000) * 0.002\n",
    "# os.makedirs('data', exist_ok=True)\n",
    "# # save to disk\n",
    "# # filename = \"data/gpt_requests.jsonl\"\n",
    "\n",
    "# # with open(filename, \"w\") as f:\n",
    "# #     for p in prompts:\n",
    "# #         json_string = json.dumps(p)\n",
    "# #         f.write(json_string + \"\\n\")\n",
    "# df['filename'].nunique()\n",
    "# len(df)\n",
    "# df.merge(meta_df.drop_duplicates(subset=['file_uid']), left_on='file_id', right_on='file_uid', how='left')['release'].value_counts()\n",
    "# df\n",
    "# # save the final df to disk\n",
    "# df.rename(columns={'social_orientation': 'social_orientation_random'}, inplace=True)\n",
    "# circumplex_dir = os.path.join(data_dir, 'transformed/circumplex')\n",
    "# os.makedirs(circumplex_dir, exist_ok=True)\n",
    "# save_filepath = os.path.join(circumplex_dir, 'gpt_prompts_r1_mini_eval_text.csv')\n",
    "# df.to_csv(save_filepath, index=False)\n",
    "# # run GPT on the prompts\n",
    "# ## Merge change points into utterances\n",
    "# # for each file_id, convert participants to numbers\n",
    "# df = df.groupby('filename', group_keys=False).apply(id_speakers)\n",
    "# df['@begin_offset'] = df['@begin_offset'].astype(int)\n",
    "# df['@char_length'] = df['@char_length'].astype(int)\n",
    "# def merge_changepoints(group_df, change_point_anno_df):\n",
    "#     # identify file_i\n",
    "#     file_id = group_df['file_id'].iloc[0]\n",
    "#     file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id].sort_values(by='timestamp')\n",
    "#     # merge in changepoint data\n",
    "#     merged_df = pd.merge_asof(group_df, file_df[['timestamp', 'impact_scalar', 'comment']], left_on='@begin_offset', right_on='timestamp', direction='nearest')\n",
    "#     # remove invalid matches\n",
    "#     # TODO: this doesn't solve for the issue of multiple changepoints in one utterance\n",
    "#     greater_equal = merged_df['@begin_offset'] <= merged_df['timestamp']\n",
    "#     less = merged_df['timestamp'] < (merged_df['@begin_offset'] + merged_df['@char_length'])\n",
    "#     merged_df.loc[~(greater_equal & less), ['timestamp', 'impact_scalar', 'comment']] = np.nan\n",
    "#     return merged_df\n",
    "# from functools import partial\n",
    "# merge_changepoints_partial = partial(merge_changepoints, change_point_anno_df=change_point_anno_df)\n",
    "# change_point_anno_df['timestamp'] = change_point_anno_df['timestamp'].astype(int)\n",
    "# file_id = 'M01000GZR'\n",
    "# file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id]\n",
    "# df = df.groupby('file_id', group_keys=False).apply(merge_changepoints_partial)\n",
    "# df['timestamp'].notnull().sum()\n",
    "# change_point_anno_df['file_id'].isin(text_file_ids).sum()\n",
    "# # check that all change points available were used\n",
    "# # assert df['timestamp'].notnull().sum() == change_point_anno_df['file_id'].isin(text_file_ids).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CHARM)",
   "language": "python",
   "name": "charm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
