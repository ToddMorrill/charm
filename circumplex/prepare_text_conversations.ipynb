{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d70db5-2545-4ee9-8162-a0743985da5d",
   "metadata": {},
   "source": [
    "# Prepare a sample from the BOLT text message corpus for Amazon Mechanical Turk labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3302a994-d1e0-4e29-b055-df1f997b932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import tiktoken\n",
    "\n",
    "from charm.data import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c8b889-b30b-4474-a390-7a9b4d6a2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata and identify text conversations that have changepoint labels\n",
    "data_dir = '/home/iron-man/Documents/data/charm'\n",
    "meta_df = pd.read_csv(os.path.join(data_dir, 'transformed/metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7d6bc1-fe73-410a-8515-e638a32d16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_annotated = meta_df['changepoint_count'] > 0\n",
    "text_modality = meta_df['modality'] == 'text'\n",
    "text_anno_df = meta_df[change_point_annotated & text_modality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f203450f-d6c9-4c07-b60c-dbdd3b36c56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_anno_df['release'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ec16bf-1231-43a6-8375-c2fdfcdfc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 'LDC2022E11_CCU_TA1_Mandarin_Chinese_Development_Source_Data_R1'\n",
    "r1_text_dir = os.path.join(data_dir, f'raw/{r1}/data/text')\n",
    "ltf_dir = os.path.join(r1_text_dir, 'ltf')\n",
    "psm_dir = os.path.join(r1_text_dir, 'psm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ac2c8b-f8eb-4f3f-be37-aae492dc3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini eval dir\n",
    "mini_eval = 'LDC2022E22_CCU_TA1_Mandarin_Chinese_Mini_Evaluation_Source_Data'\n",
    "mini_eval_text_dir = os.path.join(data_dir, f'raw/{mini_eval}/data/text')\n",
    "mini_eval_ltf_dir = os.path.join(mini_eval_text_dir, 'ltf')\n",
    "mini_eval_psm_dir = os.path.join(mini_eval_text_dir, 'psm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1dcd42-3b6a-439a-af5c-d9966277c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversation(ltf_file, psm_file):\n",
    "    # ltf_file = os.path.join(ltf_dir, ltf_file)\n",
    "    # psm_file = os.path.join(psm_dir, psm_file)\n",
    "    with open(ltf_file, 'r') as f:\n",
    "        ltf_content = f.read()\n",
    "    \n",
    "    try:\n",
    "        with open(psm_file, 'r') as f:\n",
    "            psm_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        psm_content = False\n",
    "    return ltf_content, psm_content\n",
    "\n",
    "def unpack_attributes(attribute):\n",
    "    attr_dict = {}\n",
    "    for attr in attribute:\n",
    "        attr_dict[attr['@name']] = attr['@value']\n",
    "    return attr_dict\n",
    "\n",
    "def merge_metadata(ltf_content, psm_content):\n",
    "    ltf = xmltodict.parse(ltf_content)\n",
    "    psm = xmltodict.parse(psm_content)\n",
    "    \n",
    "    # filter psm list to message attributes\n",
    "    message_attr = []\n",
    "    for d in psm['psm']['string']:\n",
    "        if d['@type'] == 'message':\n",
    "            message_attr.append(d)\n",
    "    \n",
    "    # unpack the message attributes\n",
    "    psm_df = pd.DataFrame(message_attr)\n",
    "    psm_attr_df = pd.DataFrame(psm_df['attribute'].apply(unpack_attributes).values.tolist())\n",
    "    \n",
    "    psm_df = pd.concat((psm_df.drop(columns=['attribute']), psm_attr_df), axis=1)\n",
    "    \n",
    "    ltf_df = pd.DataFrame(ltf['LCTL_TEXT']['DOC']['TEXT']['SEG'])\n",
    "    \n",
    "    # join ltf and psm on start_char\n",
    "    df = pd.merge(ltf_df, psm_df, left_on='@start_char', right_on='@begin_offset', how='left')\n",
    "    \n",
    "    # filter out messages where content length is 0 for a clean inner join\n",
    "    df = df[df['@char_length'] != '0'].reset_index(drop=True)\n",
    "    assert (len(df) == len(ltf_df))\n",
    "    # may still be missing attributes for each message\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3931d4c-9323-40df-bafb-1cbfa817e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltf_files = [os.path.join(ltf_dir, f) for f in os.listdir(ltf_dir) if f != '.DS_Store']\n",
    "psm_files = [os.path.join(psm_dir, f) for f in os.listdir(psm_dir) if f != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83e7ea4-00db-4a13-8d96-b06131ebad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mini-eval data too\n",
    "ltf_files += [os.path.join(mini_eval_ltf_dir, f) for f in os.listdir(mini_eval_ltf_dir) if f != '.DS_Store']\n",
    "psm_files += [os.path.join(mini_eval_psm_dir, f) for f in os.listdir(mini_eval_psm_dir) if f != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a58915-3b9c-4aca-a987-7364d4b8db61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1360"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ltf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1aa947-b5db-4d46-beef-cb937e421b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1360"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(psm_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ce5d1c6-16bc-404d-861d-717847cb377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "errors = []\n",
    "for ltf_file in ltf_files:\n",
    "    psm_file = ltf_file.replace('ltf', 'psm')\n",
    "    ltf_content, psm_content = load_conversation(ltf_file, psm_file)\n",
    "    if psm_content == False:\n",
    "        errors.append((ltf_file, psm_file, 'PSM file not found'))\n",
    "        continue\n",
    "    df = merge_metadata(ltf_content, psm_content)\n",
    "    \n",
    "    if len(df[df['participant'].isna()]) > 0:\n",
    "        errors.append((ltf_file, psm_file, 'Attributes missing'))\n",
    "        continue\n",
    "    \n",
    "    # retain filename\n",
    "    df.insert(0, 'filename', ltf_file)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "522f4128-41a4-4cce-bb40-5d2713c3172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(errors, columns=['ltf_file', 'psm_file', 'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "085dd5ad-21cc-49a1-aca4-2d100b450537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attributes missing    5\n",
       "Name: error, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95cc4e5e-0abe-41af-ba5e-9f097895c336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0354dbe1-9400-4446-ae84-e1c2d841731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6fcaf46-b640-4495-80d4-c5b12611a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filename'] = df['filename'].apply(lambda x: os.path.split(x)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7db9a93-582f-4737-98c9-077c8817ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of conversations\n",
    "df['filename'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c60139dc-d3d5-41f3-8549-4af3f5d7f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = text_anno_df.iloc[0]['file_uid'] + text_anno_df.iloc[0]['data_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b98e7e3-0c0a-4b01-b64e-5807677909cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df[df['filename'] == sample_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79e0d119-9e30-4e46-bb5b-af6584c27868",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df[['ORIGINAL_TEXT', 'time', 'participant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99b49bd-deff-4c6f-9cac-60b0fc7a21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.rename(columns={'ORIGINAL_TEXT':'Original Text', 'time': 'Time', 'participant': 'Participant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76c03ad3-12a6-42f9-b2af-783db0a8c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_map = {}\n",
    "speakers = ['A', 'B']\n",
    "for idx, participant in enumerate(sample_df['Participant'].unique()):\n",
    "    speaker_map[participant] = speakers[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "568bb9c7-73cd-4d1e-beea-f6a2bdbbf24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['Participant'] = sample_df['Participant'].apply(lambda x: speaker_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b69e53c6-f1bd-4698-9138-d41bc27652df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.reset_index(drop=True)\n",
    "sample_df.index.name = 'Utterance ID'\n",
    "sample_df = sample_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3eb5ed-2dba-4e88-9f45-abe9ff9b65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line(row):\n",
    "    # TODO: could optionally include the time\n",
    "    return f\"Speaker {row['Participant']} ({row['Utterance ID']}):  {row['Original Text']}\"\n",
    "\n",
    "sample_df['Complete Line'] = sample_df.apply(create_line, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "619f6e7b-aa70-49f4-8b70-9ffa5d042d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_string = '\\n'.join(sample_df['Complete Line'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fcbaabb-ca7a-458e-9799-799acb6f311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompt to prepend:\n",
    "with open('prompt.txt', 'r') as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93b4a429-dc1a-48b1-a54d-bf24819205b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 utterances at a clip to fit within ChatGPT\n",
    "prompts = []\n",
    "for i in range(0, len(sample_df), 10):\n",
    "    conversation_string = '\\n'.join(sample_df['Complete Line'].iloc[i: i+10].values.tolist())\n",
    "    prompts.append(prompt + '\\n\\n' + conversation_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e6c3177-aedf-476e-9ffe-2674456a0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chat GPT output\n",
    "chat_gpt_lines = []\n",
    "with open('ChatGPT_output.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        else:\n",
    "            chat_gpt_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ad63c8e-35c5-427b-b1e1-f7a33b2099a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt_labels = [x.split(': ')[1].split(' -')[0] for x in chat_gpt_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa94bb99-0d6c-44e6-bd85-8373967b5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt_explanations = [x.split(' - ')[1] for x in chat_gpt_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59af1cda-10b2-46af-9bc9-ef393d409594",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['chat_gpt_labels'] = chat_gpt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb537d2e-fc77-4259-85db-edc82fbd687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['chat_gpt_explanations'] = chat_gpt_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c25c9636-9136-4496-9c98-d51e8cb1b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['character_count'] = sample_df['Original Text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79d6bc1f-aca9-449b-b5d3-170954ec0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['character_count_cumsum'] = sample_df['character_count'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c0017ea-3349-4249-8f04-ce87148babf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get start/stop character intervals for each utterance\n",
    "# intervals will be [start, end)\n",
    "# start should be previous row character_count_cumsum\n",
    "# end should be start + character_count\n",
    "sample_df['start_character'] = sample_df['character_count_cumsum'].shift(1, fill_value=0.0)\n",
    "sample_df['end_character'] = sample_df['start_character'] + sample_df['character_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5693e6a6-c8a4-4e1a-90fb-c334024e0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_id = text_anno_df.iloc[0]['file_uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c28694a-92d5-4770-85d4-d4b60969586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotations\n",
    "result = utils.load_ldc_annotations(os.path.join(data_dir, 'raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2585fd90-b9dd-4773-8878-70de99873992",
   "metadata": {},
   "outputs": [],
   "source": [
    "changepoint_dfs = {}\n",
    "for anno in result:\n",
    "    changepoint_dfs[anno] = result[anno]['anno_dfs']['changepoint.tab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0468b54b-72f7-404b-8dd7-2948e2c2f43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_point_anno_df = pd.concat(changepoint_dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c211d847-6220-48b9-bd7e-ca0f6ed2ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_anno_df['timestamp'] = change_point_anno_df['timestamp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58d7ec35-30bc-4091-a5b4-c77cf1847473",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_sample_anno_df = change_point_anno_df[change_point_anno_df['file_id'] == text_anno_df.iloc[0]['file_uid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da6aa595-7a59-4e54-b8f0-cf1148ff9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.merge_asof(sample_df, change_point_sample_anno_df[['timestamp', 'impact_scalar', 'comment']], left_on='start_character', right_on='timestamp', direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2e25079-7e87-4e13-a4a5-7333f36815ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove invalid matches\n",
    "# TODO: this doesn't solve for the issue of multiple changepoints in one utterance\n",
    "greater_equal = sample_df['start_character'] <= sample_df['timestamp']\n",
    "less = sample_df['timestamp'] < sample_df['end_character']\n",
    "sample_df.loc[~(greater_equal & less), ['timestamp', 'impact_scalar', 'comment']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "865bb71a-57fb-4b35-8013-87632b5d75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = sample_df[['Utterance ID', 'Participant', 'Time', 'Original Text', 'chat_gpt_labels', 'chat_gpt_explanations','timestamp', 'impact_scalar', 'comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fea612ef-e840-475e-9af4-cf3b8f9ca53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_df.to_csv(f'{sample_file_id}_social_orientation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5186d-14d9-418e-99b9-00a1b4fdd133",
   "metadata": {},
   "source": [
    "### Save complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b53e2905-14f1-4eb4-8db1-e28d5b1d2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_transformed_dir = os.path.join(data_dir, f'transformed/{r1}/data/text')\n",
    "os.makedirs(r1_transformed_dir, exist_ok=True)\n",
    "df.to_csv(os.path.join(r1_transformed_dir, 'text.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c34331a-fbe5-4ccc-9a16-0ad90bf2634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/iron-man/Documents/data/charm/transformed/LDC2022E11_CCU_TA1_Mandarin_Chinese_Development_Source_Data_R1/data/text'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_transformed_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074969de-0468-4ad9-a0f0-d445ca24a4f0",
   "metadata": {},
   "source": [
    "### Create and save a Circumplex version of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24c5217f-42c4-4c8f-a64b-47f099e56240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "circumplex_labels = ['Assured-Dominant', 'Gregarious-Extraverted', 'Warm-Agreeable', 'Unassuming-Ingenuous', 'Unassured-Submissive', 'Aloof-Introverted', 'Cold', 'Arrogant-Calculating']\n",
    "# generate random labels for now\n",
    "df['social_orientation'] = random.choices(circumplex_labels, k=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "267c308b-16ea-4de4-a5ef-102759a2a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(r1_transformed_dir, 'text_circumplex_random.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f25c2-070f-46a0-a0e1-0ce6afcab965",
   "metadata": {},
   "source": [
    "### Create GPT prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e75e093-5d83-4584-9c97-ae95063c667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf85e52-310e-4f90-851a-38774101588f",
   "metadata": {},
   "source": [
    "### Data preparation plan\n",
    "1. Only annotate change point annotated conversations from R1 for now\n",
    "1. Convert participant IDs to speaker letters\n",
    "1. Merge in change point information\n",
    "1. Measure conversation length and split conversation into multiple chunks as needed\n",
    "1. Save to jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46d02f18-d369-4313-a9af-517183433853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label everything\n",
    "# text_anno_df = text_anno_df[text_anno_df['release'] == 'R1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27673fe8-8fb8-4090-9e92-9bfefb5c28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_ids = set(text_anno_df['file_uid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9abaf02c-6b39-4608-9d69-67f2c2f6b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter conversations df to these file_ids\n",
    "df['file_id'] = df['filename'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b57eac5-9c4d-49af-9755-ef782a06f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['file_id'].isin(text_file_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58e24880-813f-4571-ab12-08ce57d193ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['filename'] == 'M01000GZR.ltf.xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ca6520f-f525-4b60-aa1f-2e6b6d071516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_speakers(group_df):\n",
    "    speaker_map = {}\n",
    "    for idx, participant in enumerate(group_df['participant'].unique()):\n",
    "        speaker_map[participant] = idx + 1\n",
    "\n",
    "    # apply speaker map to the participant column\n",
    "    group_df['participant'] = group_df['participant'].apply(lambda x: speaker_map[x])\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39a9d179-0dd6-4789-83b6-9e83c97440a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file_id, convert participants to numbers\n",
    "df = df.groupby('filename', group_keys=False).apply(id_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68493b27-6521-468d-bdac-ef48c423d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['@begin_offset'] = df['@begin_offset'].astype(int)\n",
    "df['@char_length'] = df['@char_length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39427e89-79d8-4b72-b3e7-ee8c7463c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_changepoints(group_df, change_point_anno_df):\n",
    "    # identify file_i\n",
    "    file_id = group_df['file_id'].iloc[0]\n",
    "    file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id].sort_values(by='timestamp')\n",
    "    # merge in changepoint data\n",
    "    merged_df = pd.merge_asof(group_df, file_df[['timestamp', 'impact_scalar', 'comment']], left_on='@begin_offset', right_on='timestamp', direction='nearest')\n",
    "    # remove invalid matches\n",
    "    # TODO: this doesn't solve for the issue of multiple changepoints in one utterance\n",
    "    greater_equal = merged_df['@begin_offset'] <= merged_df['timestamp']\n",
    "    less = merged_df['timestamp'] < (merged_df['@begin_offset'] + merged_df['@char_length'])\n",
    "    merged_df.loc[~(greater_equal & less), ['timestamp', 'impact_scalar', 'comment']] = np.nan\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1061123a-2e3e-48cb-9cff-178a44fabeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f9b310d-29e3-495b-bf1d-eb2a19664c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_changepoints_partial = partial(merge_changepoints, change_point_anno_df=change_point_anno_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a1aedbf-7275-4e96-a124-2fe3b6c20b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_point_anno_df['timestamp'] = change_point_anno_df['timestamp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db8d3152-bad5-4c86-baff-d9a9da850536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_id = 'M01000GZR'\n",
    "file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac8ec790-83dc-478b-a9dc-c09d57e5e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('file_id', group_keys=False).apply(merge_changepoints_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "924b5cb8-e749-4aa8-8fd6-057402e726c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6306283-4a1e-465f-b756-561aab35f8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_point_anno_df['file_id'].isin(text_file_ids).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c2f0b43-8fe7-4b66-8bc8-dfd4ab97328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all change points available were used\n",
    "# assert df['timestamp'].notnull().sum() == change_point_anno_df['file_id'].isin(text_file_ids).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b02832ea-aa40-4ef4-87a3-6735497d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create utterance ID for each file\n",
    "def create_utterance_id(group_df):\n",
    "    group_df['Utterance ID'] = range(1, len(group_df)+1)\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccc0423d-c602-45e6-b116-5505c631b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('file_id', group_keys=False).apply(create_utterance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef432f5a-ef50-48ae-b92e-74cf31555c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create conversation turn\n",
    "def create_line(row):\n",
    "    # TODO: could optionally include the time\n",
    "    return f\"Speaker {row['participant']} ({row['Utterance ID']}):  {row['ORIGINAL_TEXT']}\"\n",
    "\n",
    "df['Complete Line'] = df.apply(create_line, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01d2c2fd-d225-45f9-98e7-c88161510000",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo-0301')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "954aeb21-73e7-494d-8327-28deae2c5caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Complete Line Length'] =  df['Complete Line'].apply(lambda x: len(encoding.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19d1e0a3-51f1-44b7-931f-ad0f0493fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_cumsum(group_df):\n",
    "    group_df['line_len_cumsum'] = group_df['Complete Line Length'].cumsum()\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5fab9459-18db-4f08-a55e-27e5cfb29241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('file_id', group_keys=False).apply(group_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e39b2d6e-1646-46a2-b023-ea656eef15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure prompt length and split as needed\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n",
    "        num_tokens = 0\n",
    "        for message in messages:\n",
    "            num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "            for key, value in message.items():\n",
    "                num_tokens += len(encoding.encode(value))\n",
    "                if key == \"name\":  # if there's a name, the role is omitted\n",
    "                    num_tokens += -1  # role is always required and always 1 token\n",
    "        num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "        return num_tokens\n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
    "    See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9bc88a5-d0a2-4c6f-945d-49d26b9934c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompt\n",
    "with open('prompt.txt', 'r') as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38b4e5e6-475f-4e54-94a1-09b23f57af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each conversation, create a message\n",
    "temp_df = df[df['file_id'] == 'M01000GE2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a2e8651-7d4d-442b-a3b3-f4348383cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_string = '\\n'.join(temp_df['Complete Line'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b40e544f-8c0f-4ad0-9e91-16fd9848c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "  {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "# check length, first check with just the prompt\n",
    "prompt_len = num_tokens_from_messages(messages)\n",
    "\n",
    "model_input = prompt + conversation_string\n",
    "# then check the whole convo and get the diff\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "  {\"role\": \"user\", \"content\": model_input},\n",
    "]\n",
    "\n",
    "input_len = num_tokens_from_messages(messages)\n",
    "\n",
    "leftover = 4_096 - input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ee1dfeb-b3e2-4567-a2d8-e323b50f7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want capacity of about 2500 tokens for the model, which means convo must be less than\n",
    "# 4,096 - 2000 - prompt_len\n",
    "convo_target_len = 4_096 - 2250 - prompt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0324946-d8ca-45ef-86f6-d69e87fa30e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72b35c86-c97c-43b7-bb9e-acb6000d9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over conversations and generate complete prompts\n",
    "prompts = []\n",
    "for file_id in df['file_id'].unique():\n",
    "    file_df = df[df['file_id'] == file_id]\n",
    "\n",
    "    # identify indices where convo chunk is approx convo_target_len\n",
    "    start = 0\n",
    "    end = convo_target_len\n",
    "    idx_end = 0\n",
    "    while idx_end+1 != len(file_df):\n",
    "        chunk_df = file_df[(file_df['line_len_cumsum'] > start) & (file_df['line_len_cumsum'] <= end)]\n",
    "        idx_start = chunk_df.iloc[0].name\n",
    "        idx_end = chunk_df.iloc[-1].name\n",
    "        \n",
    "        # create model input\n",
    "        conversation_string = '\\n'.join(file_df.iloc[idx_start:idx_end+1]['Complete Line'].values)\n",
    "        model_input = prompt + conversation_string\n",
    "        \n",
    "        messages = [\n",
    "          {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": model_input},\n",
    "        ]\n",
    "        prompts.append([file_id, messages])\n",
    "\n",
    "        # update start and end\n",
    "        start = chunk_df.iloc[-1]['line_len_cumsum']\n",
    "        end = start + convo_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b8d95477-4840-465a-8ce9-a9cd25da65f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Circumplex theory is a social psychology based theory that characterizes social interactions between speakers. The social orientation tagset includes: {Assured-Dominant, Gregarious-Extraverted, Warm-Agreeable, Unassuming-Ingenuous, Unassured-Submissive, Aloof-Introverted, Cold, Arrogant-Calculating}, which are defined below in more detail.\\n\\nAssured-Dominant - Demands to be the center of interest / Demands attention, Does most of the talking, Speaks loudly, Is firm, Is self-confident, Is forceful, Is ambitious, Is assertive, Is persistent, Is domineering, Not self-conscious\\n\\nGregarious-Extraverted - Feels comfortable around people, Starts conversations, Talks to a lot of different people, Loves large groups, Is friendly, Is enthusiastic, Is warm, Is extraverted, Is good-natured, Is cheerful / happy, Is pleasant, Is outgoing, Is approachable, Is not shy, Is \"lively\"\\n\\nWarm-Agreeable - Is interested in people, Reassures others, Inquires about others\\' well-being, Gets along well with others, Is kind, Is polite and courteous, Is sympathetic, Is respectful, Is tender-hearted, Is cooperative, Is appreciative, Is accommodating, Is gentle, Is charitable\\n\\nUnassuming-Ingenuous - Tolerates a lot from others, Takes things as they come, Tells the truth, Thinks of others first, Does not brag or boast, Seldom stretches the truth, Does not scheme or plot, Is modest, Is trustworthy, Is unassuming, Is honest, Not self-centered, Is sincere, Not demanding, Is straightforward\\n\\nUnassured-Submissive - Speaks softly, Lets others finish what they are saying, Dislikes being the center of attention, Doubts themselves, Not especially thorough, Doesn’t like to work too hard / will give up easily,  Is impractical, Is timid, Is inconsistent, Is weak, Is disorganized, Is not authoritative, Is a bit lazy, Is not forceful\\n\\nAloof-Introverted - Is quiet, especially around strangers, Is a very private person, Doesn\\'t talk a lot / Has little to say, Doesn’t smile much, Doesn’t reveal much about themselves, Is not demonstrative (verbally or non-verbally), Is distant, Is shy, Is impersonal, Is introverted, Is disinterested in others, Is bashful, Is not very social, Is focused inward\\n\\nCold - Believes people should fend for themselves, Doesn\\'t fall for sob-stories, Is not interested in other people\\'s problems, Not warm toward others, Is cruel, Is ruthless, Is cold-hearted, Is hard-hearted, Is unsympathetic, Is uncharitable\\n\\nArrogant-Calculating - Flaunts what they have, Boasts and brags, Will plot and scheme to get ahead, Willing to exploit others for own benefit, Is big-headed, Is tricky, Is boisterous, Is conniving / calculating, Is conceited, Is crafty / cunning, Is cocky, Is manipulative of others\\n---\\n\\nIn the following conversation, each line corresponds to a speaker, an utterance ID, and the text spoken. For each utterance, assign a social orientation tag, identify the utterance by its speaker and ID, and provide a brief explanation.\\n\\nSpeaker 1 (1):  你手机充300不够是吧？\\nSpeaker 2 (2):  115.51？\\nSpeaker 2 (3):  我都糊涂了\\nSpeaker 2 (4):  我打电话问问吧\\nSpeaker 1 (5):  昂\\nSpeaker 2 (6):  6月份是115块多，加上7月份的一共301块多，交305就全清了\\nSpeaker 1 (7):  您好，我现在有事不在，一会再和您联系。\\nSpeaker 1 (8):  昂\\nSpeaker 1 (9):  先充了20的快充\\nSpeaker 1 (10):  剩下的300是慢充\\nSpeaker 2 (11):  好的\\nSpeaker 1 (12):  小火车到了\\nSpeaker 2 (13):  大不，显好不\\nSpeaker 1 (14):  我又没见\\nSpeaker 2 (15):  买的多钱的来着\\nSpeaker 1 (16):  正在派件\\nSpeaker 2 (17):  周四前肯定到了\\nSpeaker 1 (18):  99\\nSpeaker 2 (19):  呃……\\nSpeaker 1 (20):  我买的还是搞活动里面最贵的\\nSpeaker 2 (21):  哦\\nSpeaker 2 (22):  那原价爱你得2，3百\\nSpeaker 1 (23):  1.8m的\\nSpeaker 1 (24):  我估计他儿玩不了\\nSpeaker 1 (25):  我选的托马斯那款\\nSpeaker 2 (26):  俺的妈呀，这么复杂啊\\nSpeaker 1 (27):  是吧\\nSpeaker 1 (28):  都是这样的\\nSpeaker 2 (29):  左旋肉碱只有一盒了\\nSpeaker 1 (30):  管事不？\\nSpeaker 2 (31):  管点事儿吧，不过最近停留在128左右了\\nSpeaker 1 (32):  哦\\nSpeaker 1 (33):  你看着办就行\\nSpeaker 2 (34):  电子照片大小怎么调整\\nSpeaker 1 (35):  美图秀秀就能改\\nSpeaker 1 (36):  我月陶菲去吃那个韩国菜了\\nSpeaker 1 (37):  你说还叫黄璐不？\\nSpeaker 2 (38):  都行啊\\nSpeaker 1 (39):  陶菲说上次宝康也给了一部分钱\\nSpeaker 1 (40):  我们是不是周四有事？\\nSpeaker 2 (41):  嗯\\nSpeaker 2 (42):  周三可以\\nSpeaker 1 (43):  你还去奥体吧？\\nSpeaker 2 (44):  不用\\nSpeaker 1 (45):  那约周三？\\nSpeaker 2 (46):  可以\\nSpeaker 2 (47):  还困啊\\nSpeaker 1 (48):  还行吧\\nSpeaker 1 (49):  再充油开发票怎么开？\\nSpeaker 2 (50):  开到一起\\nSpeaker 1 (51):  昂\\nSpeaker 1 (52):  上次的你还没要呢\\nSpeaker 2 (53):  现在不好报啊\\nSpeaker 1 (54):  嗯\\nSpeaker 1 (55):  不值当的\\nSpeaker 1 (56):  我充 的手机费到了\\nSpeaker 1 (57):  被360拦截了\\nSpeaker 1 (58):  你看看你的呢\\nSpeaker 1 (59):  一共给你充了320\\nSpeaker 2 (60):  也被拦截了，320\\nSpeaker 1 (61):  嗯\\nSpeaker 1 (62):  [图片]\\nSpeaker 1 (63):  你要是穿个这个，是不是很霸气？\\nSpeaker 1 (64):  [图片]\\nSpeaker 1 (65):  人呢？\\nSpeaker 2 (66):  昨晚我就看见了\\nSpeaker 2 (67):  刚看回去了\\nSpeaker 2 (68):  开会\\nSpeaker 1 (69):  哦\\nSpeaker 1 (70):  我去问笔记本的事情了\\nSpeaker 1 (71):  他说就是灰多了'}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "529ea842-6cdb-4f5d-b77a-42c8f8df3556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circumplex theory is a social psychology based theory that characterizes social interactions between speakers. The social orientation tagset includes: {Assured-Dominant, Gregarious-Extraverted, Warm-Agreeable, Unassuming-Ingenuous, Unassured-Submissive, Aloof-Introverted, Cold, Arrogant-Calculating}, which are defined below in more detail.\n",
      "\n",
      "Assured-Dominant - Demands to be the center of interest / Demands attention, Does most of the talking, Speaks loudly, Is firm, Is self-confident, Is forceful, Is ambitious, Is assertive, Is persistent, Is domineering, Not self-conscious\n",
      "\n",
      "Gregarious-Extraverted - Feels comfortable around people, Starts conversations, Talks to a lot of different people, Loves large groups, Is friendly, Is enthusiastic, Is warm, Is extraverted, Is good-natured, Is cheerful / happy, Is pleasant, Is outgoing, Is approachable, Is not shy, Is \"lively\"\n",
      "\n",
      "Warm-Agreeable - Is interested in people, Reassures others, Inquires about others' well-being, Gets along well with others, Is kind, Is polite and courteous, Is sympathetic, Is respectful, Is tender-hearted, Is cooperative, Is appreciative, Is accommodating, Is gentle, Is charitable\n",
      "\n",
      "Unassuming-Ingenuous - Tolerates a lot from others, Takes things as they come, Tells the truth, Thinks of others first, Does not brag or boast, Seldom stretches the truth, Does not scheme or plot, Is modest, Is trustworthy, Is unassuming, Is honest, Not self-centered, Is sincere, Not demanding, Is straightforward\n",
      "\n",
      "Unassured-Submissive - Speaks softly, Lets others finish what they are saying, Dislikes being the center of attention, Doubts themselves, Not especially thorough, Doesn’t like to work too hard / will give up easily,  Is impractical, Is timid, Is inconsistent, Is weak, Is disorganized, Is not authoritative, Is a bit lazy, Is not forceful\n",
      "\n",
      "Aloof-Introverted - Is quiet, especially around strangers, Is a very private person, Doesn't talk a lot / Has little to say, Doesn’t smile much, Doesn’t reveal much about themselves, Is not demonstrative (verbally or non-verbally), Is distant, Is shy, Is impersonal, Is introverted, Is disinterested in others, Is bashful, Is not very social, Is focused inward\n",
      "\n",
      "Cold - Believes people should fend for themselves, Doesn't fall for sob-stories, Is not interested in other people's problems, Not warm toward others, Is cruel, Is ruthless, Is cold-hearted, Is hard-hearted, Is unsympathetic, Is uncharitable\n",
      "\n",
      "Arrogant-Calculating - Flaunts what they have, Boasts and brags, Will plot and scheme to get ahead, Willing to exploit others for own benefit, Is big-headed, Is tricky, Is boisterous, Is conniving / calculating, Is conceited, Is crafty / cunning, Is cocky, Is manipulative of others\n",
      "---\n",
      "\n",
      "In the following conversation, each line corresponds to a speaker, an utterance ID, and the text spoken. For each utterance, assign a social orientation tag, identify the utterance by its speaker and ID, and provide a brief explanation.\n",
      "\n",
      "Speaker 1 (1):  你手机充300不够是吧？\n",
      "Speaker 2 (2):  115.51？\n",
      "Speaker 2 (3):  我都糊涂了\n",
      "Speaker 2 (4):  我打电话问问吧\n",
      "Speaker 1 (5):  昂\n",
      "Speaker 2 (6):  6月份是115块多，加上7月份的一共301块多，交305就全清了\n",
      "Speaker 1 (7):  您好，我现在有事不在，一会再和您联系。\n",
      "Speaker 1 (8):  昂\n",
      "Speaker 1 (9):  先充了20的快充\n",
      "Speaker 1 (10):  剩下的300是慢充\n",
      "Speaker 2 (11):  好的\n",
      "Speaker 1 (12):  小火车到了\n",
      "Speaker 2 (13):  大不，显好不\n",
      "Speaker 1 (14):  我又没见\n",
      "Speaker 2 (15):  买的多钱的来着\n",
      "Speaker 1 (16):  正在派件\n",
      "Speaker 2 (17):  周四前肯定到了\n",
      "Speaker 1 (18):  99\n",
      "Speaker 2 (19):  呃……\n",
      "Speaker 1 (20):  我买的还是搞活动里面最贵的\n",
      "Speaker 2 (21):  哦\n",
      "Speaker 2 (22):  那原价爱你得2，3百\n",
      "Speaker 1 (23):  1.8m的\n",
      "Speaker 1 (24):  我估计他儿玩不了\n",
      "Speaker 1 (25):  我选的托马斯那款\n",
      "Speaker 2 (26):  俺的妈呀，这么复杂啊\n",
      "Speaker 1 (27):  是吧\n",
      "Speaker 1 (28):  都是这样的\n",
      "Speaker 2 (29):  左旋肉碱只有一盒了\n",
      "Speaker 1 (30):  管事不？\n",
      "Speaker 2 (31):  管点事儿吧，不过最近停留在128左右了\n",
      "Speaker 1 (32):  哦\n",
      "Speaker 1 (33):  你看着办就行\n",
      "Speaker 2 (34):  电子照片大小怎么调整\n",
      "Speaker 1 (35):  美图秀秀就能改\n",
      "Speaker 1 (36):  我月陶菲去吃那个韩国菜了\n",
      "Speaker 1 (37):  你说还叫黄璐不？\n",
      "Speaker 2 (38):  都行啊\n",
      "Speaker 1 (39):  陶菲说上次宝康也给了一部分钱\n",
      "Speaker 1 (40):  我们是不是周四有事？\n",
      "Speaker 2 (41):  嗯\n",
      "Speaker 2 (42):  周三可以\n",
      "Speaker 1 (43):  你还去奥体吧？\n",
      "Speaker 2 (44):  不用\n",
      "Speaker 1 (45):  那约周三？\n",
      "Speaker 2 (46):  可以\n",
      "Speaker 2 (47):  还困啊\n",
      "Speaker 1 (48):  还行吧\n",
      "Speaker 1 (49):  再充油开发票怎么开？\n",
      "Speaker 2 (50):  开到一起\n",
      "Speaker 1 (51):  昂\n",
      "Speaker 1 (52):  上次的你还没要呢\n",
      "Speaker 2 (53):  现在不好报啊\n",
      "Speaker 1 (54):  嗯\n",
      "Speaker 1 (55):  不值当的\n",
      "Speaker 1 (56):  我充 的手机费到了\n",
      "Speaker 1 (57):  被360拦截了\n",
      "Speaker 1 (58):  你看看你的呢\n",
      "Speaker 1 (59):  一共给你充了320\n",
      "Speaker 2 (60):  也被拦截了，320\n",
      "Speaker 1 (61):  嗯\n",
      "Speaker 1 (62):  [图片]\n",
      "Speaker 1 (63):  你要是穿个这个，是不是很霸气？\n",
      "Speaker 1 (64):  [图片]\n",
      "Speaker 1 (65):  人呢？\n",
      "Speaker 2 (66):  昨晚我就看见了\n",
      "Speaker 2 (67):  刚看回去了\n",
      "Speaker 2 (68):  开会\n",
      "Speaker 1 (69):  哦\n",
      "Speaker 1 (70):  我去问笔记本的事情了\n",
      "Speaker 1 (71):  他说就是灰多了\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0][-1][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8d350f9-ca5c-400a-9243-f5217fe64b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate cost\n",
    "token_count = 0\n",
    "for p in prompts:\n",
    "    token_count += num_tokens_from_messages(p[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f777fffc-0fb2-49f4-9c66-16a70f08e99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.674286"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# price\n",
    "(token_count / 1000) * 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3fb8f282-52b2-4a24-afc4-8a3a5d2b7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "# filename = \"data/gpt_requests.jsonl\"\n",
    "\n",
    "# with open(filename, \"w\") as f:\n",
    "#     for p in prompts:\n",
    "#         json_string = json.dumps(p)\n",
    "#         f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9130e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filename'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e297c6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34558"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8c9c435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R1           20864\n",
       "Mini-Eval    13694\n",
       "Name: release, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(meta_df.drop_duplicates(subset=['file_uid']), left_on='file_id', right_on='file_uid', how='left')['release'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b7486ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final df to disk\n",
    "df.rename(columns={'social_orientation': 'social_orientation_random'}, inplace=True)\n",
    "df.to_csv('data/df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run GPT on the prompts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CHARM)",
   "language": "python",
   "name": "charm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
