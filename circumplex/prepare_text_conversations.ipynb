{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d70db5-2545-4ee9-8162-a0743985da5d",
   "metadata": {},
   "source": [
    "# Prepare documents to be labeled with social orientation tags by GPT\n",
    "TODO:\n",
    "- this whole notebook can probably be optimized by work with Pandas dataframes instead of the data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3302a994-d1e0-4e29-b055-df1f997b932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from collections import deque\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "\n",
    "from charm.data import utils as charm_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "84eeff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which model to use\n",
    "model = 'gpt-3.5-turbo'\n",
    "token_limit = 4096\n",
    "# model = 'gpt-4'\n",
    "# token_limit = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2bd78fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle file\n",
    "data = utils.load_pickle(os.path.expanduser('~/Documents/data/charm/transformed/tm3229-cache.pkl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a5f25c2-070f-46a0-a0e1-0ce6afcab965",
   "metadata": {},
   "source": [
    "## Create GPT prompts\n",
    "Data preparation plan\n",
    "1. Convert participant IDs to speaker numbers\n",
    "1. Only annotate LDC annotated regions\n",
    "1. Prepare the data for all splits in chunks of 100 conversations\n",
    "    1. Prioritize internal train and val splits for starters\n",
    "1. Assess prices of processing everything\n",
    "1. Measure conversation length and split conversation into multiple chunks as needed\n",
    "1. Save to jsonl\n",
    "1. Merge in change point information (won't repeat this exercise due to concerns about the incorrectness of timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7ca6520f-f525-4b60-aa1f-2e6b6d071516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_speakers_convo(group_df):\n",
    "    \"\"\"Give each speaker a numerical identifier.\"\"\"\n",
    "    if 'participant' not in group_df.columns:\n",
    "        group_df['participant_id'] = 'unknown'\n",
    "        return group_df\n",
    "    \n",
    "    # fillna with unknown\n",
    "    group_df['participant'] = group_df['participant'].fillna('unknown')\n",
    "\n",
    "    speaker_map = {'unknown': 'unknown'}\n",
    "    participants = set(group_df['participant'].unique())\n",
    "    # exclude unknown so we don't give it an ID number\n",
    "    if 'unknown' in participants:\n",
    "        participants.remove('unknown')\n",
    "    for idx, participant in enumerate(participants):\n",
    "        speaker_map[participant] = idx + 1\n",
    "\n",
    "    # apply speaker map to the participant column\n",
    "    group_df['participant_id'] = group_df['participant'].apply(lambda x: speaker_map[x])\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559938fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_markdown(df):\n",
    "    \"\"\"Converts each row of a pandas dataframe to markdown delimited by | with a single space on each side.\n",
    "    There is also a row of dashes between the header and the table body.\n",
    "    \"\"\"\n",
    "    header = '| ' + ' | '.join(df.columns) + ' |'\n",
    "    dashes = '| ' + ' | '.join(['---' for _ in df.columns]) + ' |'\n",
    "    data = '\\n'.join(['| ' + ' | '.join([str(x) for x in row]) + ' |' for row in df.values])\n",
    "    return '\\n'.join([header, dashes, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e454550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "503066cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create conversation row in markdown format\n",
    "def create_line(row):\n",
    "    content = f\"| {row['utterance_id']} | {row['participant_id']} | {row['text']} |\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b823a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gpt_lines(data, transcript='whisper'):\n",
    "    \"\"\"Records the following data in the data dict:\n",
    "        1. Gives a numeric ID to each speaker in a transcript\n",
    "        2. Creates utterance IDs for each utterance in a transcript\n",
    "        3. Creates a complete line that will be sent to GPT\n",
    "    \"\"\"\n",
    "    # for all file_ids, add a participant_id value to utterances\n",
    "    unprocessed = []\n",
    "    for file_id in tqdm(data.keys()):\n",
    "        if not data[file_id]['processed']:\n",
    "            unprocessed.append(file_id)\n",
    "            continue\n",
    "        # if data_type == 'text', don't need whisper key\n",
    "        if data[file_id]['data_type'] == 'text':\n",
    "            temp_df = pd.DataFrame(data[file_id]['utterances'])\n",
    "        else:\n",
    "            temp_df = pd.DataFrame(data[file_id]['utterances'][transcript])\n",
    "        \n",
    "        # add participant_id\n",
    "        temp_df = id_speakers_convo(temp_df)\n",
    "        # add utterance_id\n",
    "        # sort by start to be safe\n",
    "        temp_df = temp_df.sort_values(by='start', ascending=True)\n",
    "        temp_df = temp_df.reset_index(drop=True)\n",
    "        temp_df['utterance_id'] = temp_df.index + 1\n",
    "        # create GPT line\n",
    "        temp_df['gpt_line'] = temp_df.apply(create_line, axis=1)\n",
    "\n",
    "        # persist results\n",
    "        # if data_type == 'text', don't need whisper key\n",
    "        if data[file_id]['data_type'] == 'text':\n",
    "            # save results back to data\n",
    "            data[file_id]['utterances'] = temp_df.to_dict('records')\n",
    "        else:\n",
    "            # save results back to data\n",
    "            data[file_id]['utterances'][transcript] = temp_df.to_dict('records')\n",
    "    return data, unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fae00372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [01:07<00:00, 148.14it/s]\n"
     ]
    }
   ],
   "source": [
    "data, unprocessed = prepare_gpt_lines(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0edf775",
   "metadata": {},
   "source": [
    "## Create GPT chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f2dc89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompt\n",
    "with open('prompt.txt', 'r') as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f91d225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need some descriptive stats on distribution of conversation lengths in terms of encoding length\n",
    "encoding = tiktoken.encoding_for_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ecc76286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last two lines of the prompt and add the speaker unknown prompt\n",
    "# prompt_speaker_unknown = '\\n'.join(prompt.split('\\n')[:-2]) + '\\n' + prompt_speaker_unknown\n",
    "# model_input = prompt + '\\n'.join(sample_df['Complete Line'].tolist()) + '\\n\\nOutput:\\n'\n",
    "# model_input_speaker_unknown = prompt_speaker_unknown + '\\n'.join(sample_df['Complete Line (Unknown Speaker)'].tolist()) + '\\n\\nOutput:\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4a760f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_length = len(encoding.encode(prompt))\n",
    "# prompt_speaker_unknown_length = len(encoding.encode(prompt_speaker_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "17316c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 1180\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt length: {prompt_length}\")\n",
    "# print(f\"Prompt (speaker unknown) length: {prompt_speaker_unknown_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e76ec051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max conversation input length (excluding prompt): 1944\n",
      "Maximum total length: 3124\n",
      "which means we're leaving 972 tokens for the response.\n"
     ]
    }
   ],
   "source": [
    "# GPT4 has a max length of 8192 so leave some fraction of generative capacity for the response\n",
    "# ie. (8192 - prompt length) / 2 = max length of input\n",
    "max_input_length = int((token_limit - len(encoding.encode(prompt))) / 1.5)\n",
    "print(f\"Max conversation input length (excluding prompt): {max_input_length}\")\n",
    "print(f'Maximum total length: {max_input_length + prompt_length}')\n",
    "print(f\"which means we're leaving {token_limit - max_input_length - prompt_length} tokens for the response.\")\n",
    "# max_input_length_no_speaker = int((token_limit - len(encoding.encode(prompt_speaker_unknown))) / 2)\n",
    "# print(f\"Max conversation input length (no speaker, excluding prompt): {max_input_length_no_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "79dd23a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [04:33<00:00, 36.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# create conversation chunks (again could probably speed this up with a DF and some indexing)\n",
    "# encode conversations with GPT-4 tokenizer\n",
    "# could probably do this faster if everything was in a single list/df\n",
    "convo_turn_lengths = []\n",
    "convo_encoding_lengths = []\n",
    "for file_id in tqdm(data.keys()):\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    if data[file_id]['data_type'] == 'text':\n",
    "        temp_df = pd.DataFrame(data[file_id]['utterances'])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data[file_id]['utterances']['whisper'])\n",
    "    \n",
    "    # filter temp_df to only annotated regions\n",
    "    # not doing this because of issues with Whisper timestamps\n",
    "    # temp_df = temp_df[(temp_df['start'] >= data[file_id]['start']) & (temp_df['end'] <= data[file_id]['end'])]\n",
    "    \n",
    "    convo_turn_lengths.append((file_id, data[file_id]['data_type'], len(temp_df)))\n",
    "    encoding_length = 0\n",
    "    encoding_lengths = []\n",
    "    encoding_cum_sum = []\n",
    "    encoded_content = encoding.encode_batch(temp_df['gpt_line'].values.tolist())\n",
    "    for encoded_line in encoded_content:\n",
    "        encoding_length += len(encoded_line)\n",
    "        encoding_lengths.append(len(encoded_line))\n",
    "        encoding_cum_sum.append(encoding_length)\n",
    "    temp_df['encoding_length'] = encoding_lengths\n",
    "    temp_df['encoding_cumsum'] = encoding_cum_sum\n",
    "    convo_encoding_lengths.append((file_id, data[file_id]['data_type'], encoding_length))\n",
    "\n",
    "    # save cumsum info back to data\n",
    "    if data[file_id]['data_type'] == 'text':\n",
    "        # save results back to data\n",
    "        data[file_id]['utterances'] = temp_df.to_dict('records')\n",
    "    else:\n",
    "        # save results back to data\n",
    "        data[file_id]['utterances']['whisper'] = temp_df.to_dict('records')\n",
    "    \n",
    "    # use the cumsum information to create dialog chunks with overlapping utterances for continuity\n",
    "    # identify indices where convo chunk is approx max_input_length\n",
    "    max_size = max_input_length #  if data[file_id]['data_type'] == 'text' else max_input_length_no_speaker\n",
    "    utterances = data[file_id]['utterances'] if data[file_id]['data_type'] == 'text' else data[file_id]['utterances']['whisper']\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    n_overlap = 10\n",
    "    last_n = deque([], maxlen=n_overlap)\n",
    "    idx_end = 0\n",
    "    while idx_end != len(utterances):\n",
    "        # mental model is to create a chunk that is as close to max_input_length as possible\n",
    "        # then move the idx_end to 10 utterances before idx_end to get some overlap and repeat\n",
    "        current_chunk.append(utterances[idx_end])\n",
    "        current_size += utterances[idx_end]['encoding_length']\n",
    "        last_n.append(utterances[idx_end]['encoding_length'])\n",
    "\n",
    "        # record chunk if filled or at end of utterances\n",
    "        if (current_size > max_size) or (idx_end == (len(utterances) - 1)):\n",
    "            # if the most recent n turns are too long, then don't reset idx_end, just continue\n",
    "            # prevents infinite loop\n",
    "            # or if at the end of the utterances, then don't reset idx_end\n",
    "            if (sum(last_n) > max_size) or (idx_end == (len(utterances) - 1)):\n",
    "                idx_end = idx_end\n",
    "            else:\n",
    "                idx_end = max(0, idx_end - n_overlap) # get some overlap with 10 previous utterances\n",
    "            # reset trackers\n",
    "            last_n.clear()\n",
    "            current_size = 0\n",
    "            chunks.append(current_chunk) \n",
    "            current_chunk = []\n",
    "        \n",
    "        # advance idx_end\n",
    "        idx_end += 1\n",
    "    \n",
    "    # save chunks back to data\n",
    "    data[file_id]['gpt_prompts'] = chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e9aaf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_turn_lengths_df = pd.DataFrame(convo_turn_lengths, columns=['file_id', 'data_type', 'num_turns'])\n",
    "convo_encoding_lengths_df = pd.DataFrame(convo_encoding_lengths, columns=['file_id', 'data_type', 'encoding_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3f921c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">num_turns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>727.0</td>\n",
       "      <td>360.052270</td>\n",
       "      <td>308.962545</td>\n",
       "      <td>16.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>3640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>83.787776</td>\n",
       "      <td>70.766406</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>7474.0</td>\n",
       "      <td>394.418651</td>\n",
       "      <td>369.629549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>4905.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_turns                                                           \n",
       "              count        mean         std   min    25%    50%    75%     max\n",
       "data_type                                                                     \n",
       "audio         727.0  360.052270  308.962545  16.0  215.0  293.0  374.0  3640.0\n",
       "text         1767.0   83.787776   70.766406  15.0   40.0   64.0  105.0   959.0\n",
       "video        7474.0  394.418651  369.629549   1.0  204.0  311.0  475.0  4905.0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_turn_lengths_df.groupby('data_type').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "28d934c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">encoding_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>727.0</td>\n",
       "      <td>6753.785420</td>\n",
       "      <td>5942.334067</td>\n",
       "      <td>278.0</td>\n",
       "      <td>4345.50</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>6316.50</td>\n",
       "      <td>76383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>2719.804188</td>\n",
       "      <td>2339.874657</td>\n",
       "      <td>392.0</td>\n",
       "      <td>1319.00</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>3221.00</td>\n",
       "      <td>25172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>7474.0</td>\n",
       "      <td>8064.415173</td>\n",
       "      <td>7085.909304</td>\n",
       "      <td>231.0</td>\n",
       "      <td>4231.25</td>\n",
       "      <td>6063.5</td>\n",
       "      <td>9154.75</td>\n",
       "      <td>92697.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          encoding_length                                                    \\\n",
       "                    count         mean          std    min      25%     50%   \n",
       "data_type                                                                     \n",
       "audio               727.0  6753.785420  5942.334067  278.0  4345.50  5080.0   \n",
       "text               1767.0  2719.804188  2339.874657  392.0  1319.00  1941.0   \n",
       "video              7474.0  8064.415173  7085.909304  231.0  4231.25  6063.5   \n",
       "\n",
       "                             \n",
       "               75%      max  \n",
       "data_type                    \n",
       "audio      6316.50  76383.0  \n",
       "text       3221.00  25172.0  \n",
       "video      9154.75  92697.0  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_encoding_lengths_df.groupby('data_type').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "52ba8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check distribution of chunk lengths\n",
    "chunk_lengths = []\n",
    "for file_id in data.keys():\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    chunk_lengths.append((file_id, data[file_id]['data_type'], len(data[file_id]['gpt_prompts'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1666b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">num_chunks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>727.0</td>\n",
       "      <td>4.243466</td>\n",
       "      <td>3.395408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>1.985286</td>\n",
       "      <td>1.584112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>7474.0</td>\n",
       "      <td>4.980198</td>\n",
       "      <td>4.083549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_chunks                                              \n",
       "               count      mean       std  min  25%  50%  75%   max\n",
       "data_type                                                         \n",
       "audio          727.0  4.243466  3.395408  1.0  3.0  3.0  4.0  44.0\n",
       "text          1767.0  1.985286  1.584112  1.0  1.0  1.0  2.0  18.0\n",
       "video         7474.0  4.980198  4.083549  1.0  3.0  4.0  6.0  53.0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(chunk_lengths, columns=['file_id', 'data_type', 'num_chunks']).groupby('data_type').describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a814904",
   "metadata": {},
   "source": [
    "### Create Final GPT Prompts, Break into 100 Conversation Splits, Assess Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "71ba9aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EVALUATION_LDC2023E07', 'INTERNAL_TEST', 'INTERNAL_TRAIN', 'INTERNAL_VAL'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split by train/val/test/eval\n",
    "# use the speaker unknown prompt for the video and audio data\n",
    "# get all splits\n",
    "splits = set()\n",
    "for file_id in data.keys():\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    # union with existing splits\n",
    "    splits = splits.union(data[file_id]['splits'])\n",
    "    \n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cbc273ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10008/10008 [00:01<00:00, 8738.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train_prompts = []\n",
    "val_prompts = []\n",
    "test_prompts = []\n",
    "eval_prompts = []\n",
    "markdown_header = '| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |'\n",
    "output_markdown_header = '| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |'\n",
    "for file_id in tqdm(data):\n",
    "    if not data[file_id]['processed']:\n",
    "        continue\n",
    "    # retrieve chunks\n",
    "    chunks = data[file_id]['gpt_prompts']\n",
    "    preamble = prompt # if data[file_id]['data_type'] == 'text' else prompt_speaker_unknown\n",
    "    file_gpt_messages = []\n",
    "    for chunk in chunks:        \n",
    "        final_prompt = preamble + markdown_header + '\\n'.join([utterance['gpt_line'] for utterance in chunk]) + '\\n\\nOutput:\\n' + output_markdown_header\n",
    "        # format GPT messages\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": final_prompt},\n",
    "            ]\n",
    "        file_gpt_messages.append([file_id, messages])\n",
    "    \n",
    "    if 'INTERNAL_TRAIN' in data[file_id]['splits']:\n",
    "        train_prompts.extend(file_gpt_messages)\n",
    "    elif 'INTERNAL_VAL' in data[file_id]['splits']:\n",
    "        val_prompts.extend(file_gpt_messages)\n",
    "    elif 'INTERNAL_TEST' in data[file_id]['splits']:\n",
    "        test_prompts.extend(file_gpt_messages)\n",
    "    elif 'EVALUATION_LDC2023E07' in data[file_id]['splits']:\n",
    "        eval_prompts.extend(file_gpt_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ef7a0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tally up unique file ids in each split to make sure we have the right number\n",
    "train_file_id_count = len(set([file_id for file_id, _ in train_prompts]))\n",
    "val_file_id_count = len(set([file_id for file_id, _ in val_prompts]))\n",
    "test_file_id_count = len(set([file_id for file_id, _ in test_prompts]))\n",
    "eval_file_id_count = len(set([file_id for file_id, _ in eval_prompts]))\n",
    "processed_file_count = len([file_id for file_id in data.keys() if data[file_id]['processed']])\n",
    "assert train_file_id_count + val_file_id_count + test_file_id_count + eval_file_id_count == processed_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ad7d60bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 5 5 56\n"
     ]
    }
   ],
   "source": [
    "# split each split into chunks of 100 file_ids randomly by using a hash function\n",
    "train_hash_buckets = train_file_id_count // 100\n",
    "val_hash_buckets = val_file_id_count // 100\n",
    "test_hash_buckets = test_file_id_count // 100\n",
    "eval_hash_buckets = eval_file_id_count // 100\n",
    "print(train_hash_buckets, val_hash_buckets, test_hash_buckets, eval_hash_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "96ed60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_to_hash_bucket(prompts, num_file_ids_per_bucket=100):\n",
    "    file_id_count = len(set([file_id for file_id, _ in prompts]))\n",
    "    num_hash_buckets = file_id_count // num_file_ids_per_bucket\n",
    "    # loop through files and assign to hash buckets\n",
    "    shards = {}\n",
    "    for file_id, messages in prompts:\n",
    "        hash_bucket = int(hashlib.sha256(file_id.encode('utf-8')).hexdigest(), 16) % num_hash_buckets\n",
    "        if hash_bucket not in shards:\n",
    "            shards[hash_bucket] = []\n",
    "        shards[hash_bucket].append([file_id, messages])\n",
    "    return shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "568560bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shards = assign_to_hash_bucket(train_prompts)\n",
    "val_shards = assign_to_hash_bucket(val_prompts)\n",
    "test_shards = assign_to_hash_bucket(test_prompts)\n",
    "eval_shards = assign_to_hash_bucket(eval_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "571c38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that the total number of messages in train_shards matches train_prompts\n",
    "assert sum([len(train_shards[key]) for key in train_shards.keys()]) == len(train_prompts)\n",
    "assert sum([len(val_shards[key]) for key in val_shards.keys()]) == len(val_prompts)\n",
    "assert sum([len(test_shards[key]) for key in test_shards.keys()]) == len(test_prompts)\n",
    "assert sum([len(eval_shards[key]) for key in eval_shards.keys()]) == len(eval_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a5bb5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total cost\n",
    "def calculate_cost(data, shard, prompt_length, model='gpt-4'):\n",
    "    total_prompt_tokens = 0\n",
    "    estimated_output_tokens = 0\n",
    "    for file_id, messages in shard:\n",
    "        input_len = utils.num_tokens_from_messages(messages, model=model)\n",
    "        total_prompt_tokens += input_len\n",
    "        prompt_len_ = prompt_length #if data[file_id]['data_type'] == 'text' else prompt_speaker_unknown_length\n",
    "        # responses seem to be much shorter than prompts\n",
    "        estimated_output_tokens += (input_len - prompt_len_) / 2 # probably an overestimate\n",
    "    # cost per 1000 tokens\n",
    "    prompt_cost = 0.03 if model == 'gpt-4' else 0.002\n",
    "    response_cost = 0.06 if model == 'gpt-4' else 0.002\n",
    "    input_cost = ((total_prompt_tokens/1000)*prompt_cost)\n",
    "    output_cost = ((estimated_output_tokens/1000)*response_cost)\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1662de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_costs = {}\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    shard_costs[name] = {}\n",
    "    for shard in split.keys():\n",
    "        shard_costs[name][shard] = calculate_cost(data, split[shard], prompt_length, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4dec7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert shard costs to a dataframe\n",
    "shard_costs_df = pd.DataFrame(shard_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b8cc2c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.389581</td>\n",
       "      <td>2.881935</td>\n",
       "      <td>2.827814</td>\n",
       "      <td>3.662169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.418410</td>\n",
       "      <td>0.333303</td>\n",
       "      <td>0.587876</td>\n",
       "      <td>0.483605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.311293</td>\n",
       "      <td>2.374274</td>\n",
       "      <td>2.051378</td>\n",
       "      <td>2.475134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.119823</td>\n",
       "      <td>2.737488</td>\n",
       "      <td>2.539347</td>\n",
       "      <td>3.375422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.404490</td>\n",
       "      <td>2.972742</td>\n",
       "      <td>2.723682</td>\n",
       "      <td>3.632168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.685683</td>\n",
       "      <td>3.160986</td>\n",
       "      <td>3.379450</td>\n",
       "      <td>3.936942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.040951</td>\n",
       "      <td>3.164184</td>\n",
       "      <td>3.445211</td>\n",
       "      <td>4.919923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train       val      test       eval\n",
       "count  33.000000  5.000000  5.000000  56.000000\n",
       "mean    3.389581  2.881935  2.827814   3.662169\n",
       "std     0.418410  0.333303  0.587876   0.483605\n",
       "min     2.311293  2.374274  2.051378   2.475134\n",
       "25%     3.119823  2.737488  2.539347   3.375422\n",
       "50%     3.404490  2.972742  2.723682   3.632168\n",
       "75%     3.685683  3.160986  3.379450   3.936942\n",
       "max     4.040951  3.164184  3.445211   4.919923"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_costs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4a34b6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    111.856164\n",
       "val       14.409674\n",
       "test      14.139068\n",
       "eval     205.081466\n",
       "dtype: float64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_costs_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8b14fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve 1 document of each type from train_shard 0\n",
    "video = None\n",
    "text = None\n",
    "audio = None\n",
    "for file_id, messages in train_shards[0]:\n",
    "    if data[file_id]['data_type'] == 'video':\n",
    "        video = file_id\n",
    "    elif data[file_id]['data_type'] == 'text':\n",
    "        text = file_id\n",
    "    elif data[file_id]['data_type'] == 'audio':\n",
    "        audio = file_id\n",
    "\n",
    "video_messages = []\n",
    "audio_messages = []\n",
    "text_messages = []\n",
    "# retain all the messages for these selected files\n",
    "for file_id, messages in train_prompts:\n",
    "    if file_id == video:\n",
    "        video_messages.append([file_id, messages])\n",
    "    elif file_id == audio:\n",
    "        audio_messages.append([file_id, messages])\n",
    "    elif file_id == text:\n",
    "        text_messages.append([file_id, messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ea09583b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M010008RY',\n",
       "  [{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Circumplex theory is a social psychology based theory that characterizes social interactions between speakers. The social orientation tagset includes: {Assured-Dominant, Gregarious-Extraverted, Warm-Agreeable, Unassuming-Ingenuous, Unassured-Submissive, Aloof-Introverted, Cold, Arrogant-Calculating}, which are defined below in more detail.\\n\\nAssured-Dominant - Demands to be the center of interest, demands attention, does most of the talking, speaks loudly, is firm, is self-confident, is forceful, is ambitious, is assertive, is persistent, is domineering, not self-conscious\\n\\nGregarious-Extraverted - Feels comfortable around people, starts conversations, talks to a lot of different people, loves large groups, is friendly, is enthusiastic, is warm, is extraverted, is good-natured, is cheerful / happy, is pleasant, is outgoing, is approachable, is not shy, is \"lively\"\\n\\nWarm-Agreeable - is interested in people, reassures others, inquires about others\\' well-being, gets along well with others, is kind, is polite and courteous, is sympathetic, is respectful, is tender-hearted, is cooperative, is appreciative, is accommodating, is gentle, is charitable\\n\\nUnassuming-Ingenuous - Tolerates a lot from others, takes things as they come, tells the truth, thinks of others first, does not brag or boast, seldom stretches the truth, does not scheme or plot, is modest, is trustworthy, is unassuming, is honest, not self-centered, is sincere, not demanding, is straightforward\\n\\nUnassured-Submissive - Speaks softly, lets others finish what they are saying, dislikes being the center of attention, doubts themselves, not especially thorough, doesn’t like to work too hard / will give up easily, is impractical, is timid, is inconsistent, is weak, is disorganized, is not authoritative, is a bit lazy, is not forceful\\n\\nAloof-Introverted - Is quiet, especially around strangers, is a very private person, doesn\\'t talk a lot / has little to say, doesn’t smile much, doesn’t reveal much about themselves, is not demonstrative (verbally or non-verbally), is distant, is shy, is impersonal, is introverted, is disinterested in others, is bashful, is not very social, is focused inward\\n\\nCold - Believes people should fend for themselves, doesn\\'t fall for sob-stories, is not interested in other people\\'s problems, not warm toward others, is cruel, is ruthless, is cold-hearted, is hard-hearted, is unsympathetic, is uncharitable\\n\\nArrogant-Calculating - Flaunts what they have, boasts and brags, will plot and scheme to get ahead, willing to exploit others for own benefit, is big-headed, is tricky, is boisterous, is conniving / calculating, is conceited, is crafty / cunning, is cocky, is manipulative of others\\n---\\nIn the following conversation, each row corresponds to an Utterance ID, a Speaker ID, and the Text spoken. For each utterance, assign a social orientation tag. Identify the utterance by its Utterance ID and Speaker ID. For example, here is the expected input and output format for a sample conversation.\\n\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |\\n| 1 | 1 | 在不 (手机QQ可以视频聊天啦! http://mobile.qq.com ) |\\n| 2 | 2 | 在 |\\n| 3 | 1 | 今天和姨妈视频来着，刚知道这些事 |\\n| 4 | 2 | 我很无奈 |\\n| 5 | 2 | 真是不明白，本来他沾光的事情，怎么就成了这样了 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |\\n| 1 | 1 | Aloof-Introverted |\\n| 2 | 2 | Unassured-Submissive |\\n| 3 | 1 | Warm-Agreeable |\\n| 4 | 2 | Unassured-Submissive |\\n| 5 | 2 | Cold |\\n---\\nIt\\'s also possible that a speaker number is unknown for an utterance, in which case you should assign Speaker IDs to the utterances. Many conversations will have 2 speakers but some will have 3 or more. For example, here is the expected input and output format for such a conversation.\\n\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |\\n| 6 | unknown | 你知道吗 |\\n| 7 | unknown | 对对他就问我 |\\n| 8 | unknown | 我说我这阵子比较忙 |\\n| 9 | unknown | 我也没有 |\\n| 10 | unknown | 本来我想的那个跟你写个信的 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |\\n| 6 | 1 | Warm-Agreeable |\\n| 7 | 2 | Warm-Agreeable |\\n| 8 | 2 | Unassured-Submissive |\\n| 9 | 2 | Unassured-Submissive |\\n| 10 | 2 | Warm-Agreeable |\\n---\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- || 1 | unknown | 喂喂喂还可以啊 |\\n| 2 | unknown | 你去可以能打 |\\n| 3 | unknown | 我就告诉谁说的 |\\n| 4 | unknown | 在网站上说的吗 |\\n| 5 | unknown | 好像看见一个我看见有他那个q a |\\n| 6 | unknown | 那个部分有一个人就说 |\\n| 7 | unknown | 他说我能够带他 |\\n| 8 | unknown | 我能够带他几个 |\\n| 9 | unknown | 那我不知道 |\\n| 10 | unknown | 他就是他就是问你说如果比如打够15个 |\\n| 11 | unknown | 然后又没有 |\\n| 12 | unknown | 没有就是没接到5个那种外就是外语 |\\n| 13 | unknown | 那个非英语的那个电话 |\\n| 14 | unknown | 然后就再给你机会 |\\n| 15 | unknown | 对他这么说他可以他没在就说 |\\n| 16 | unknown | 专门为了要接那个非英语的单 |\\n| 17 | unknown | 他说你可以继续打 |\\n| 18 | unknown | 好像有这么一说 |\\n| 19 | unknown | 嗯 |\\n| 20 | unknown | 哎那要不算这个就好了 |\\n| 21 | unknown | 然后我第一个不走钻 |\\n| 22 | unknown | 我第一个不是英语说的吗 |\\n| 23 | unknown | 啊有可能很有很有可能会吗 |\\n| 24 | unknown | 我觉得很有可能 |\\n| 25 | unknown | 哎不过就差那么一两块钱 |\\n| 26 | unknown | 哈哈哈哈对你跟他说我第一个作废可以吗 |\\n| 27 | unknown | 然后你说什么 |\\n| 28 | unknown | 你说你跟他讲你说我第一个那个 |\\n| 29 | unknown | 用英语讲那个作废 |\\n| 30 | unknown | 然后保留那个全中文 |\\n| 31 | unknown | 不知道不知道嗯 |\\n| 32 | unknown | 你那你那细胞怎么回事啊 |\\n| 33 | unknown | 你你那个在你身边吗 |\\n| 34 | unknown | 在在我先拿着呢啊 |\\n| 35 | unknown | 嗯 |\\n| 36 | unknown | 说啊哎我以为你在准备的好 |\\n| 37 | unknown | 第一个扣是就是part one的一个最上面是不是要填2006啊 |\\n| 38 | unknown | 嗯嗯嗯 |\\n| 39 | unknown | 然后名字那个你说第二个空天那个对 |\\n| 40 | unknown | 第二个就是对对对对 |\\n| 41 | unknown | 然后地址 |\\n| 42 | unknown | 嗯 |\\n| 43 | unknown | 这都没问题 |\\n| 44 | unknown | 你看那个9a |\\n| 45 | unknown | 9a啊那个car |\\n| 46 | unknown | carman |\\n| 47 | unknown | immigrant state |\\n| 48 | unknown | 嗯 |\\n| 49 | unknown | 我就是iphone啊你是什么 |\\n| 50 | unknown | 就跟跟那个签证一样啊就写成了对啊对啊就是你签证类型 |\\n| 51 | unknown | 我写的student |\\n| 52 | unknown | 就写f1的 |\\n| 53 | unknown | 好像不应该写student的吧 |\\n| 54 | unknown | 对啊对我刚开始是我就是看他那写的我就想啊是不是写学生 |\\n| 55 | unknown | 你看他那个我看他那个instruction上写的好像要写你的对可能是要写钱对对就是跟第六个我觉得又重了我就不是明白 |\\n| 56 | unknown | 第六个是什么好吧 |\\n| 57 | unknown | 第六个就问你签证类啊第六个我姐姐也是iPhone |\\n| 58 | unknown | 嗯我就写两个iPhone是吧 |\\n| 59 | unknown | 对对哎真是好我还真是没什么意思 |\\n| 60 | unknown | 对啊为什么要重呢 |\\n| 61 | unknown | 然后 |\\n| 62 | unknown | 然后这个9b是ds |\\n| 63 | unknown | 10呢 |\\n| 64 | unknown | 就是10是应该是画那个check号是吧 |\\n| 65 | unknown | 10是check啊 |\\n| 66 | unknown | 对啊 |\\n| 67 | unknown | 他下边哪个9你刚问我哪个了 |\\n| 68 | unknown | b9b9b是应该写ds |\\n| 69 | unknown | ds什么叫ds |\\n| 70 | unknown | during of status |\\n| 71 | unknown | 9b啊就是那个 |\\n| 72 | unknown | 那怎么写ds我就写一个日期 |\\n| 73 | unknown | 那也可以都可以 |\\n| 74 | unknown | 你写日期也可以写ds也可以就跟那个i94表上那一样 |\\n| 75 | unknown | 哦哦哦那个没关系 |\\n| 76 | unknown | 第十个你应该画check了吧 |\\n| 77 | unknown | 十个check然后以后什么都不用填了就贴那个 |\\n| 78 | unknown | 然后就签个名写个日期就行了 |\\n| 79 | unknown | 后面的都不用填是吧 |\\n| 80 | unknown | 那个part2都不用填 |\\n| 81 | unknown | 嗯我我不知道你要不要填 |\\n| 82 | unknown | 我不知道我们俩是不是会不一样啊 |\\n| 83 | unknown | 因为你跟我的情况也是一样 |\\n| 84 | unknown | 我不知道 |\\n| 85 | unknown | 应该不用吧 |\\n| 86 | unknown | 你看的instruction我都没看instruction |\\n| 87 | unknown | instruction我看不明白 |\\n| 88 | unknown | 啊你就等于第二张第二张你都没写是吧 |\\n| 89 | unknown | 就直接填个名字就行了 |\\n| 90 | unknown | 对都没写 |\\n| 91 | unknown | 啊 |\\n| 92 | unknown | 他说可以 |\\n| 93 | unknown | 嗯 |\\n| 94 | unknown | 第十个又弄一个你看他十 |\\n| 95 | unknown | 其实下面还有一行字说的 |\\n| 96 | unknown | 啊还要什么有那个要attach一个statement什么玩意 |\\n| 97 | unknown | 你也没给你没attach什么 |\\n| 98 | unknown | 我根本就没看instruction |\\n| 99 | unknown | instruction说什么 |\\n| 100 | unknown | 他说 |\\n| 101 | unknown | 他又给instruction又refer到另外一个地方去 |\\n| 102 | unknown | 他说你要你要attach这个表 |\\n| 103 | unknown | 那个表我没看见 |\\n| 104 | unknown | 然后他说那个东西他也没给连接 |\\n| 105 | unknown | 我也不知道在哪 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |'}]],\n",
       " ['M010008RY',\n",
       "  [{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Circumplex theory is a social psychology based theory that characterizes social interactions between speakers. The social orientation tagset includes: {Assured-Dominant, Gregarious-Extraverted, Warm-Agreeable, Unassuming-Ingenuous, Unassured-Submissive, Aloof-Introverted, Cold, Arrogant-Calculating}, which are defined below in more detail.\\n\\nAssured-Dominant - Demands to be the center of interest, demands attention, does most of the talking, speaks loudly, is firm, is self-confident, is forceful, is ambitious, is assertive, is persistent, is domineering, not self-conscious\\n\\nGregarious-Extraverted - Feels comfortable around people, starts conversations, talks to a lot of different people, loves large groups, is friendly, is enthusiastic, is warm, is extraverted, is good-natured, is cheerful / happy, is pleasant, is outgoing, is approachable, is not shy, is \"lively\"\\n\\nWarm-Agreeable - is interested in people, reassures others, inquires about others\\' well-being, gets along well with others, is kind, is polite and courteous, is sympathetic, is respectful, is tender-hearted, is cooperative, is appreciative, is accommodating, is gentle, is charitable\\n\\nUnassuming-Ingenuous - Tolerates a lot from others, takes things as they come, tells the truth, thinks of others first, does not brag or boast, seldom stretches the truth, does not scheme or plot, is modest, is trustworthy, is unassuming, is honest, not self-centered, is sincere, not demanding, is straightforward\\n\\nUnassured-Submissive - Speaks softly, lets others finish what they are saying, dislikes being the center of attention, doubts themselves, not especially thorough, doesn’t like to work too hard / will give up easily, is impractical, is timid, is inconsistent, is weak, is disorganized, is not authoritative, is a bit lazy, is not forceful\\n\\nAloof-Introverted - Is quiet, especially around strangers, is a very private person, doesn\\'t talk a lot / has little to say, doesn’t smile much, doesn’t reveal much about themselves, is not demonstrative (verbally or non-verbally), is distant, is shy, is impersonal, is introverted, is disinterested in others, is bashful, is not very social, is focused inward\\n\\nCold - Believes people should fend for themselves, doesn\\'t fall for sob-stories, is not interested in other people\\'s problems, not warm toward others, is cruel, is ruthless, is cold-hearted, is hard-hearted, is unsympathetic, is uncharitable\\n\\nArrogant-Calculating - Flaunts what they have, boasts and brags, will plot and scheme to get ahead, willing to exploit others for own benefit, is big-headed, is tricky, is boisterous, is conniving / calculating, is conceited, is crafty / cunning, is cocky, is manipulative of others\\n---\\nIn the following conversation, each row corresponds to an Utterance ID, a Speaker ID, and the Text spoken. For each utterance, assign a social orientation tag. Identify the utterance by its Utterance ID and Speaker ID. For example, here is the expected input and output format for a sample conversation.\\n\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |\\n| 1 | 1 | 在不 (手机QQ可以视频聊天啦! http://mobile.qq.com ) |\\n| 2 | 2 | 在 |\\n| 3 | 1 | 今天和姨妈视频来着，刚知道这些事 |\\n| 4 | 2 | 我很无奈 |\\n| 5 | 2 | 真是不明白，本来他沾光的事情，怎么就成了这样了 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |\\n| 1 | 1 | Aloof-Introverted |\\n| 2 | 2 | Unassured-Submissive |\\n| 3 | 1 | Warm-Agreeable |\\n| 4 | 2 | Unassured-Submissive |\\n| 5 | 2 | Cold |\\n---\\nIt\\'s also possible that a speaker number is unknown for an utterance, in which case you should assign Speaker IDs to the utterances. Many conversations will have 2 speakers but some will have 3 or more. For example, here is the expected input and output format for such a conversation.\\n\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |\\n| 6 | unknown | 你知道吗 |\\n| 7 | unknown | 对对他就问我 |\\n| 8 | unknown | 我说我这阵子比较忙 |\\n| 9 | unknown | 我也没有 |\\n| 10 | unknown | 本来我想的那个跟你写个信的 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |\\n| 6 | 1 | Warm-Agreeable |\\n| 7 | 2 | Warm-Agreeable |\\n| 8 | 2 | Unassured-Submissive |\\n| 9 | 2 | Unassured-Submissive |\\n| 10 | 2 | Warm-Agreeable |\\n---\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- || 96 | unknown | 啊还要什么有那个要attach一个statement什么玩意 |\\n| 97 | unknown | 你也没给你没attach什么 |\\n| 98 | unknown | 我根本就没看instruction |\\n| 99 | unknown | instruction说什么 |\\n| 100 | unknown | 他说 |\\n| 101 | unknown | 他又给instruction又refer到另外一个地方去 |\\n| 102 | unknown | 他说你要你要attach这个表 |\\n| 103 | unknown | 那个表我没看见 |\\n| 104 | unknown | 然后他说那个东西他也没给连接 |\\n| 105 | unknown | 我也不知道在哪 |\\n| 106 | unknown | 哎你就算了你不管他了 |\\n| 107 | unknown | 你就把 |\\n| 108 | unknown | 就这样啊ok |\\n| 109 | unknown | 然后你问他行不行 |\\n| 110 | unknown | 他说行了就行 |\\n| 111 | unknown | 要不行的话你就再往再进 |\\n| 112 | unknown | 反正也没有什么着急 |\\n| 113 | unknown | 行行行 |\\n| 114 | unknown | 嗯 |\\n| 115 | unknown | 我估计这一点都不重要 |\\n| 116 | unknown | 他就是留个底儿 |\\n| 117 | unknown | 然后可能就怕万一有什么事儿了 |\\n| 118 | unknown | 有什么纠纷什么的 |\\n| 119 | unknown | 我觉得应该是没有人管 |\\n| 120 | unknown | 那这两碗吧明年报税也不报了 |\\n| 121 | unknown | 哪没用 |\\n| 122 | unknown | 两碗吧 |\\n| 123 | unknown | 报税啊 |\\n| 124 | unknown | 报税反正我是我们报税 |\\n| 125 | unknown | 我我从来都没有报过这个东西 |\\n| 126 | unknown | 哦 |\\n| 127 | unknown | 因为我现在还是算是non-resident |\\n| 128 | unknown | 就是报税的时候 |\\n| 129 | unknown | 好像就这些都不用报 |\\n| 130 | unknown | 然后你就是在美国待了几年以上 |\\n| 131 | unknown | 五年还是几年以上忘了 |\\n| 132 | unknown | 才算是resident |\\n| 133 | unknown | 然后你就其他你也都要报 |\\n| 134 | unknown | 比如说你什么赌博啊 |\\n| 135 | unknown | 什么中彩票什么的 |\\n| 136 | unknown | 好像就都要报 |\\n| 137 | unknown | 但我好像我们现在好像不用 |\\n| 138 | unknown | 这些其实也 |\\n| 139 | unknown | 我不知道 |\\n| 140 | unknown | 我现在报的就是那个工资 |\\n| 141 | unknown | 工资表上那些东西 |\\n| 142 | unknown | 对你就报那就可以了 |\\n| 143 | unknown | 别的你也没有啊 |\\n| 144 | unknown | 你有什么别的 |\\n| 145 | unknown | 别的银行存款也有利息 |\\n| 146 | unknown | 利息我不知道要不要交税 |\\n| 147 | unknown | 好像他们都也不用交 |\\n| 148 | unknown | 但是那个 |\\n| 149 | unknown | 有就是但是一般不会 |\\n| 150 | unknown | 他有个有一个那个下限 |\\n| 151 | unknown | 你要低于那个你就不用报 |\\n| 152 | unknown | 每年如果银行给你寄那个statement了 |\\n| 153 | unknown | 那那个就要报 |\\n| 154 | unknown | 他今天我寄了 |\\n| 155 | unknown | 给你寄了 |\\n| 156 | unknown | 他今天我寄了我也没报 |\\n| 157 | unknown | 你今年的已经报完了是吗 |\\n| 158 | unknown | 对报完了已经寄过去了 |\\n| 159 | unknown | 但你说他是能查出来的是吗 |\\n| 160 | unknown | 没事问题不大 |\\n| 161 | unknown | 你几块钱的东西 |\\n| 162 | unknown | 他就会来找你麻烦 |\\n| 163 | unknown | 但是理论上好像是应该报的 |\\n| 164 | unknown | 那个那个银行那个是应该报 |\\n| 165 | unknown | 我肯定没问题 |\\n| 166 | unknown | 我这几天就是这就在忙着睡的事 |\\n| 167 | unknown | 我今天下午还得去 |\\n| 168 | unknown | 没麻烦吗 |\\n| 169 | unknown | 你报了多少张表 |\\n| 170 | unknown | 我们就三三三公斤吗 |\\n| 171 | unknown | Federal的 |\\n| 172 | unknown | 然后local的 |\\n| 173 | unknown | 然后一个state |\\n| 174 | unknown | 就是周税周税和联邦税 |\\n| 175 | unknown | 还有什么 |\\n| 176 | unknown | 还有个地方税 |\\n| 177 | unknown | local的 |\\n| 178 | unknown | 你们得报仨啊 |\\n| 179 | unknown | 那你每一份就几张表 |\\n| 180 | unknown | 每一份里面就是一两张表 |\\n| 181 | unknown | 然后那个有一份 |\\n| 182 | unknown | local还需要加上你的iphone |\\n| 183 | unknown | 提供硬件 |\\n| 184 | unknown | 还有Visa |\\n| 185 | unknown | 学校也是不是给你一个w2表 |\\n| 186 | unknown | w2表 |\\n| 187 | unknown | 然后你填的是什么表 |\\n| 188 | unknown | 你填还填什么表 |\\n| 189 | unknown | 填1042 |\\n| 190 | unknown | 我填的是1042EZ |\\n| 191 | unknown | 那个表 |\\n| 192 | unknown | 1042不是1042N什么什么 |\\n| 193 | unknown | NREZ |\\n| 194 | unknown | 对那个 |\\n| 195 | unknown | 1040还是402 |\\n| 196 | unknown | 1042我记得是 |\\n| 197 | unknown | 42NREZ |\\n| 198 | unknown | 对 |\\n| 199 | unknown | 然后加上w2就完了 |\\n| 200 | unknown | 对 |\\n| 201 | unknown | 好 |\\n| 202 | unknown | 还有那个什么8842 |\\n| 203 | unknown | 啊 |\\n| 204 | unknown | 8842我记得还有 |\\n| 205 | unknown | 也是和联邦税一块的 |\\n| 206 | unknown | 对 |\\n| 207 | unknown | 那可能差不多 |\\n| 208 | unknown | 都是这几个表 |\\n| 209 | unknown | 你们能反多少税啊 |\\n| 210 | unknown | 我今年因为我 |\\n| 211 | unknown | 为什么我比较care这事 |\\n| 212 | unknown | 就是因为 |\\n| 213 | unknown | 我我想多退一点嘛 |\\n| 214 | unknown | 因为好像据说有一个说法 |\\n| 215 | unknown | 就是你 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |'}]],\n",
       " ['M010008RY',\n",
       "  [{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Circumplex theory is a social psychology based theory that characterizes social interactions between speakers. The social orientation tagset includes: {Assured-Dominant, Gregarious-Extraverted, Warm-Agreeable, Unassuming-Ingenuous, Unassured-Submissive, Aloof-Introverted, Cold, Arrogant-Calculating}, which are defined below in more detail.\\n\\nAssured-Dominant - Demands to be the center of interest, demands attention, does most of the talking, speaks loudly, is firm, is self-confident, is forceful, is ambitious, is assertive, is persistent, is domineering, not self-conscious\\n\\nGregarious-Extraverted - Feels comfortable around people, starts conversations, talks to a lot of different people, loves large groups, is friendly, is enthusiastic, is warm, is extraverted, is good-natured, is cheerful / happy, is pleasant, is outgoing, is approachable, is not shy, is \"lively\"\\n\\nWarm-Agreeable - is interested in people, reassures others, inquires about others\\' well-being, gets along well with others, is kind, is polite and courteous, is sympathetic, is respectful, is tender-hearted, is cooperative, is appreciative, is accommodating, is gentle, is charitable\\n\\nUnassuming-Ingenuous - Tolerates a lot from others, takes things as they come, tells the truth, thinks of others first, does not brag or boast, seldom stretches the truth, does not scheme or plot, is modest, is trustworthy, is unassuming, is honest, not self-centered, is sincere, not demanding, is straightforward\\n\\nUnassured-Submissive - Speaks softly, lets others finish what they are saying, dislikes being the center of attention, doubts themselves, not especially thorough, doesn’t like to work too hard / will give up easily, is impractical, is timid, is inconsistent, is weak, is disorganized, is not authoritative, is a bit lazy, is not forceful\\n\\nAloof-Introverted - Is quiet, especially around strangers, is a very private person, doesn\\'t talk a lot / has little to say, doesn’t smile much, doesn’t reveal much about themselves, is not demonstrative (verbally or non-verbally), is distant, is shy, is impersonal, is introverted, is disinterested in others, is bashful, is not very social, is focused inward\\n\\nCold - Believes people should fend for themselves, doesn\\'t fall for sob-stories, is not interested in other people\\'s problems, not warm toward others, is cruel, is ruthless, is cold-hearted, is hard-hearted, is unsympathetic, is uncharitable\\n\\nArrogant-Calculating - Flaunts what they have, boasts and brags, will plot and scheme to get ahead, willing to exploit others for own benefit, is big-headed, is tricky, is boisterous, is conniving / calculating, is conceited, is crafty / cunning, is cocky, is manipulative of others\\n---\\nIn the following conversation, each row corresponds to an Utterance ID, a Speaker ID, and the Text spoken. For each utterance, assign a social orientation tag. Identify the utterance by its Utterance ID and Speaker ID. For example, here is the expected input and output format for a sample conversation.\\n\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |\\n| 1 | 1 | 在不 (手机QQ可以视频聊天啦! http://mobile.qq.com ) |\\n| 2 | 2 | 在 |\\n| 3 | 1 | 今天和姨妈视频来着，刚知道这些事 |\\n| 4 | 2 | 我很无奈 |\\n| 5 | 2 | 真是不明白，本来他沾光的事情，怎么就成了这样了 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |\\n| 1 | 1 | Aloof-Introverted |\\n| 2 | 2 | Unassured-Submissive |\\n| 3 | 1 | Warm-Agreeable |\\n| 4 | 2 | Unassured-Submissive |\\n| 5 | 2 | Cold |\\n---\\nIt\\'s also possible that a speaker number is unknown for an utterance, in which case you should assign Speaker IDs to the utterances. Many conversations will have 2 speakers but some will have 3 or more. For example, here is the expected input and output format for such a conversation.\\n\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- |\\n| 6 | unknown | 你知道吗 |\\n| 7 | unknown | 对对他就问我 |\\n| 8 | unknown | 我说我这阵子比较忙 |\\n| 9 | unknown | 我也没有 |\\n| 10 | unknown | 本来我想的那个跟你写个信的 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |\\n| 6 | 1 | Warm-Agreeable |\\n| 7 | 2 | Warm-Agreeable |\\n| 8 | 2 | Unassured-Submissive |\\n| 9 | 2 | Unassured-Submissive |\\n| 10 | 2 | Warm-Agreeable |\\n---\\nInput:\\n| Utterance ID | Speaker ID | Text |\\n| --- | --- | --- || 206 | unknown | 对 |\\n| 207 | unknown | 那可能差不多 |\\n| 208 | unknown | 都是这几个表 |\\n| 209 | unknown | 你们能反多少税啊 |\\n| 210 | unknown | 我今年因为我 |\\n| 211 | unknown | 为什么我比较care这事 |\\n| 212 | unknown | 就是因为 |\\n| 213 | unknown | 我我想多退一点嘛 |\\n| 214 | unknown | 因为好像据说有一个说法 |\\n| 215 | unknown | 就是你 |\\n| 216 | unknown | 你上学这个 |\\n| 217 | unknown | 你原来在加州交税了 |\\n| 218 | unknown | 然后你上学以后 |\\n| 219 | unknown | 你付的这个教育的这个钱 |\\n| 220 | unknown | 可以可以可以退税啊 |\\n| 221 | unknown | 还是抵税的 |\\n| 222 | unknown | 就能应该能退不少 |\\n| 223 | unknown | 所以就涉及到这个问题 |\\n| 224 | unknown | 要是如果光是就是 |\\n| 225 | unknown | 就是这个平常那些 |\\n| 226 | unknown | 我也不太care |\\n| 227 | unknown | 这次我想主要想多退点 |\\n| 228 | unknown | 你们是你们是也有就是那个什么 |\\n| 229 | unknown | 就是中美5000块钱 |\\n| 230 | unknown | 那个什么协议 |\\n| 231 | unknown | 那个你们也有吗 |\\n| 232 | unknown | 什么5000块钱 |\\n| 233 | unknown | 就是就是说中美有一个协议 |\\n| 234 | unknown | 就是说在中国的留学生 |\\n| 235 | unknown | 每年收入前5000块钱 |\\n| 236 | unknown | 是不收税的 |\\n| 237 | unknown | 是吗 |\\n| 238 | unknown | 对 |\\n| 239 | unknown | 啊 |\\n| 240 | unknown | 我还真不知道啊 |\\n| 241 | unknown | 有这个协议啊 |\\n| 242 | unknown | 那你们那个 |\\n| 243 | unknown | 你这个贴这个钱 |\\n| 244 | unknown | 就是说超过5000的部分 |\\n| 245 | unknown | 其实也要交税 |\\n| 246 | unknown | 对超过5000还是要交的 |\\n| 247 | unknown | 每每月系里帮你们扣了吗 |\\n| 248 | unknown | 还是什么 |\\n| 249 | unknown | 每个月他我们今年是没扣 |\\n| 250 | unknown | 所以这个就是无所谓了 |\\n| 251 | unknown | 我们去年是都扣了 |\\n| 252 | unknown | 所以返回来特别多 |\\n| 253 | unknown | 今年就没扣 |\\n| 254 | unknown | 今年工资就比比去年要多 |\\n| 255 | unknown | 因为他扣的少了 |\\n| 256 | unknown | 啊 |\\n| 257 | unknown | 但你可能这次要补一点是吗 |\\n| 258 | unknown | 对啊 |\\n| 259 | unknown | 这次也不用补 |\\n| 260 | unknown | 也是退了 |\\n| 261 | unknown | 啊也退退退退退少了 |\\n| 262 | unknown | 去年退了那种一天 |\\n| 263 | unknown | 一天多钱 |\\n| 264 | unknown | 今年也就100块钱 |\\n| 265 | unknown | 好 |\\n| 266 | unknown | 哎呀对啊 |\\n| 267 | unknown | 我想多退一点 |\\n| 268 | unknown | 多退点还能 |\\n| 269 | unknown | 哎 |\\n| 270 | unknown | 你们是不是有这种软件 |\\n| 271 | unknown | 就是在网上可以直接贴那种 |\\n| 272 | unknown | Federal的 |\\n| 273 | unknown | 嗯 |\\n| 274 | unknown | 我不知道啊 |\\n| 275 | unknown | 你那是网上报的吗 |\\n| 276 | unknown | 在哪儿 |\\n| 277 | unknown | 就在网上有一个 |\\n| 278 | unknown | 嗯 |\\n| 279 | unknown | 我不知道你们去你们学校 |\\n| 280 | unknown | 应该给你们弄 |\\n| 281 | unknown | 就是我们学校 |\\n| 282 | unknown | 给我们每个人发了一个 |\\n| 283 | unknown | 就是呃密码 |\\n| 284 | unknown | 那种是要付费的应该是 |\\n| 285 | unknown | 然后学校他统一给买了这个 |\\n| 286 | unknown | 这个软件这样子 |\\n| 287 | unknown | define |\\n| 288 | unknown | 对 |\\n| 289 | unknown | 对 |\\n| 290 | unknown | 然后然后就是每个人有一个密码 |\\n| 291 | unknown | 密码都是一样的 |\\n| 292 | unknown | 全校都是一样的 |\\n| 293 | unknown | 就你在学校的密码 |\\n| 294 | unknown | 然后你上来之后就可以在网上 |\\n| 295 | unknown | 在线填就是联邦的那个那两个表 |\\n| 296 | unknown | 然后他自动给你生成 |\\n| 297 | unknown | 你就选择在天 |\\n| 298 | unknown | 很方便的就是 |\\n| 299 | unknown | 那你给联邦的就等于什么 |\\n| 300 | unknown | hard copy也不用寄了是吧 |\\n| 301 | unknown | 不是他不能在网上提交 |\\n| 302 | unknown | 怎么在网上填表 |\\n| 303 | unknown | 你还得把它打印出来 |\\n| 304 | unknown | 再寄啊 |\\n| 305 | unknown | 就但是有些计算的 |\\n| 306 | unknown | 那是直接对 |\\n| 307 | unknown | 计算你就不用算了 |\\n| 308 | unknown | 对啊 |\\n| 309 | unknown | 那你就是要把那表打印出来 |\\n| 310 | unknown | 然后再打印出来 |\\n| 311 | unknown | 然后寄过去就行了 |\\n| 312 | unknown | 但是那个local的和那个周税 |\\n| 313 | unknown | 都得另外手填 |\\n| 314 | unknown | 那那表你去哪弄呢 |\\n| 315 | unknown | 表有个这网上可以 |\\n| 316 | unknown | 但我们学校就是他到到 |\\n\\nOutput:\\n| Utterance ID | Speaker ID | Label |\\n| --- | --- | --- |'}]]]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6f4fffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./M010008RY.flac'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert this video and audio file to .mp4 and .flac, respectively\n",
    "charm_utils.strip_ldc_header('./M01004WNG.mp4.ldcc', './')\n",
    "charm_utils.strip_ldc_header('./M010008RY.flac.ldcc', './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "db806881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve Whisper transcripts for these two files and save to csv\n",
    "M01004WNG_df = pd.DataFrame(data['M01004WNG']['utterances']['whisper'])\n",
    "M01004WNG_df.to_csv('./M01004WNG_whisper.csv', index=False)\n",
    "M010008RY_df = pd.DataFrame(data['M010008RY']['utterances']['whisper'])\n",
    "M010008RY_df.to_csv('./M010008RY_whisper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3b019475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data directory\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b5f05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these messages to a jsonl file, train_shard_0_sample.jsonl\n",
    "with open('./data/train_shard_0_sample.jsonl', 'w') as f:\n",
    "    all_messages = video_messages + audio_messages + text_messages\n",
    "    for m in all_messages:\n",
    "        json_string = json.dumps(m)\n",
    "        f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc7da52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_utterances(data, shard):\n",
    "    # get all unique file ids in this shard\n",
    "    file_ids = set([file_id for file_id, _ in shard])\n",
    "    # count the number of utterances in the actual prompt and then compare to the number of utterances in the file\n",
    "    actual_utterances = 0\n",
    "    gpt_utterances = 0\n",
    "    for file_id in file_ids:\n",
    "        utterances = data[file_id]['utterances'] if data[file_id]['data_type'] == 'text' else data[file_id]['utterances']['whisper']\n",
    "        actual_utterances += len(utterances)\n",
    "    # get the number of utterances in the gpt prompt\n",
    "    for file_id, messages in shard:\n",
    "        gpt_utterances += len(messages[1]['content'].split('Input:\\n')[-1].split('\\n')[:-3])\n",
    "        \n",
    "    return actual_utterances, gpt_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20c187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tally up how many utterances are in each shard\n",
    "shard_utterances_counts = {}\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    shard_utterances_counts[name] = {}\n",
    "    for shard in split.keys():\n",
    "        actual_utterances, gpt_utterances = count_utterances(data, split[shard])\n",
    "        shard_utterances_counts[name][shard] = {'actual_utterances': actual_utterances, 'gpt_utterances': gpt_utterances}['actual_utterances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20cd58f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_counts = pd.DataFrame(shard_utterances_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a1eccb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26043.484848</td>\n",
       "      <td>30825.20000</td>\n",
       "      <td>29979.200000</td>\n",
       "      <td>39182.839286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3461.614048</td>\n",
       "      <td>3491.59687</td>\n",
       "      <td>6456.704322</td>\n",
       "      <td>5274.111271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18954.000000</td>\n",
       "      <td>25032.00000</td>\n",
       "      <td>21889.000000</td>\n",
       "      <td>28260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23331.000000</td>\n",
       "      <td>30891.00000</td>\n",
       "      <td>26640.000000</td>\n",
       "      <td>35823.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25981.000000</td>\n",
       "      <td>31050.00000</td>\n",
       "      <td>28578.000000</td>\n",
       "      <td>38715.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28687.000000</td>\n",
       "      <td>33507.00000</td>\n",
       "      <td>34680.000000</td>\n",
       "      <td>42641.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34865.000000</td>\n",
       "      <td>33646.00000</td>\n",
       "      <td>38109.000000</td>\n",
       "      <td>52794.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train          val          test          eval\n",
       "count     33.000000      5.00000      5.000000     56.000000\n",
       "mean   26043.484848  30825.20000  29979.200000  39182.839286\n",
       "std     3461.614048   3491.59687   6456.704322   5274.111271\n",
       "min    18954.000000  25032.00000  21889.000000  28260.000000\n",
       "25%    23331.000000  30891.00000  26640.000000  35823.750000\n",
       "50%    25981.000000  31050.00000  28578.000000  38715.500000\n",
       "75%    28687.000000  33507.00000  34680.000000  42641.750000\n",
       "max    34865.000000  33646.00000  38109.000000  52794.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbd70f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shards to disk\n",
    "for name, split in [('train', train_shards), ('val', val_shards), ('test', test_shards), ('eval', eval_shards)]:\n",
    "    for shard in split.keys():\n",
    "        with open(f'./data/{name}_shard_{shard}.jsonl', 'w') as f:\n",
    "            for file_id, messages in split[shard]:\n",
    "                json_string = json.dumps([file_id, messages])\n",
    "                f.write(json_string + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b25207ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated pickle file\n",
    "with open(os.path.expanduser('~/Documents/data/charm/transformed/tm3229-cache-updated.json'), 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f7dbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete files, as needed\n",
    "# import glob\n",
    "# for name in ['train', 'val', 'test', 'eval']:\n",
    "#     for file in glob.glob(f'./data/{name}_shard_*'):\n",
    "#         os.remove(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d7962c7",
   "metadata": {},
   "source": [
    "### Graveyard (old code) - though some of this may be much faster (e.g. using a DF instead of a list of dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "954aeb21-73e7-494d-8327-28deae2c5caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['Complete Line Length'] =  df['Complete Line'].apply(lambda x: len(encoding.encode(x)))\n",
    "# def group_cumsum(group_df):\n",
    "#     group_df['line_len_cumsum'] = group_df['Complete Line Length'].cumsum()\n",
    "#     return group_df\n",
    "# df = df.groupby('file_id', group_keys=False).apply(group_cumsum)\n",
    "# # for each conversation, create a message\n",
    "# temp_df = df[df['file_id'] == 'M01000GE2']\n",
    "# conversation_string = '\\n'.join(temp_df['Complete Line'].values)\n",
    "# messages = [\n",
    "#   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#   {\"role\": \"user\", \"content\": prompt},\n",
    "# ]\n",
    "\n",
    "# # check length, first check with just the prompt\n",
    "# prompt_len = num_tokens_from_messages(messages)\n",
    "\n",
    "# model_input = prompt + conversation_string\n",
    "# # then check the whole convo and get the diff\n",
    "# messages = [\n",
    "#   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#   {\"role\": \"user\", \"content\": model_input},\n",
    "# ]\n",
    "\n",
    "# input_len = num_tokens_from_messages(messages)\n",
    "\n",
    "# leftover = 4_096 - input_len\n",
    "# # want capacity of about 2500 tokens for the model, which means convo must be less than\n",
    "# # 4,096 - 2000 - prompt_len\n",
    "# convo_target_len = 4_096 - 2250 - prompt_len\n",
    "# convo_target_len\n",
    "# # loop over conversations and generate complete prompts\n",
    "# prompts = []\n",
    "# for file_id in df['file_id'].unique():\n",
    "#     file_df = df[df['file_id'] == file_id]\n",
    "\n",
    "#     # identify indices where convo chunk is approx convo_target_len\n",
    "#     start = 0\n",
    "#     end = convo_target_len\n",
    "#     idx_end = 0\n",
    "#     while idx_end+1 != len(file_df):\n",
    "#         chunk_df = file_df[(file_df['line_len_cumsum'] > start) & (file_df['line_len_cumsum'] <= end)]\n",
    "#         idx_start = chunk_df.iloc[0].name\n",
    "#         idx_end = chunk_df.iloc[-1].name\n",
    "        \n",
    "#         # create model input\n",
    "#         conversation_string = '\\n'.join(file_df.iloc[idx_start:idx_end+1]['Complete Line'].values)\n",
    "#         model_input = prompt + conversation_string\n",
    "        \n",
    "#         messages = [\n",
    "#           {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\"},\n",
    "#           {\"role\": \"user\", \"content\": model_input},\n",
    "#         ]\n",
    "#         prompts.append([file_id, messages])\n",
    "\n",
    "#         # update start and end\n",
    "#         start = chunk_df.iloc[-1]['line_len_cumsum']\n",
    "#         end = start + convo_target_len\n",
    "# prompts[0][1]\n",
    "# print(prompts[0][-1][-1]['content'])\n",
    "# # estimate cost\n",
    "# token_count = 0\n",
    "# for p in prompts:\n",
    "#     token_count += num_tokens_from_messages(p[-1])\n",
    "# # price\n",
    "# (token_count / 1000) * 0.002\n",
    "# os.makedirs('data', exist_ok=True)\n",
    "# # save to disk\n",
    "# # filename = \"data/gpt_requests.jsonl\"\n",
    "\n",
    "# # with open(filename, \"w\") as f:\n",
    "# #     for p in prompts:\n",
    "# #         json_string = json.dumps(p)\n",
    "# #         f.write(json_string + \"\\n\")\n",
    "# df['filename'].nunique()\n",
    "# len(df)\n",
    "# df.merge(meta_df.drop_duplicates(subset=['file_uid']), left_on='file_id', right_on='file_uid', how='left')['release'].value_counts()\n",
    "# df\n",
    "# # save the final df to disk\n",
    "# df.rename(columns={'social_orientation': 'social_orientation_random'}, inplace=True)\n",
    "# circumplex_dir = os.path.join(data_dir, 'transformed/circumplex')\n",
    "# os.makedirs(circumplex_dir, exist_ok=True)\n",
    "# save_filepath = os.path.join(circumplex_dir, 'gpt_prompts_r1_mini_eval_text.csv')\n",
    "# df.to_csv(save_filepath, index=False)\n",
    "# # run GPT on the prompts\n",
    "# ## Merge change points into utterances\n",
    "# # for each file_id, convert participants to numbers\n",
    "# df = df.groupby('filename', group_keys=False).apply(id_speakers)\n",
    "# df['@begin_offset'] = df['@begin_offset'].astype(int)\n",
    "# df['@char_length'] = df['@char_length'].astype(int)\n",
    "# def merge_changepoints(group_df, change_point_anno_df):\n",
    "#     # identify file_i\n",
    "#     file_id = group_df['file_id'].iloc[0]\n",
    "#     file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id].sort_values(by='timestamp')\n",
    "#     # merge in changepoint data\n",
    "#     merged_df = pd.merge_asof(group_df, file_df[['timestamp', 'impact_scalar', 'comment']], left_on='@begin_offset', right_on='timestamp', direction='nearest')\n",
    "#     # remove invalid matches\n",
    "#     # TODO: this doesn't solve for the issue of multiple changepoints in one utterance\n",
    "#     greater_equal = merged_df['@begin_offset'] <= merged_df['timestamp']\n",
    "#     less = merged_df['timestamp'] < (merged_df['@begin_offset'] + merged_df['@char_length'])\n",
    "#     merged_df.loc[~(greater_equal & less), ['timestamp', 'impact_scalar', 'comment']] = np.nan\n",
    "#     return merged_df\n",
    "# from functools import partial\n",
    "# merge_changepoints_partial = partial(merge_changepoints, change_point_anno_df=change_point_anno_df)\n",
    "# change_point_anno_df['timestamp'] = change_point_anno_df['timestamp'].astype(int)\n",
    "# file_id = 'M01000GZR'\n",
    "# file_df = change_point_anno_df[change_point_anno_df['file_id'] == file_id]\n",
    "# df = df.groupby('file_id', group_keys=False).apply(merge_changepoints_partial)\n",
    "# df['timestamp'].notnull().sum()\n",
    "# change_point_anno_df['file_id'].isin(text_file_ids).sum()\n",
    "# # check that all change points available were used\n",
    "# # assert df['timestamp'].notnull().sum() == change_point_anno_df['file_id'].isin(text_file_ids).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CHARM)",
   "language": "python",
   "name": "charm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
